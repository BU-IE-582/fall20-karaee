{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "<span style=\"font-size:1.25em\"> Emre Kara  </span>  \n",
    "<span style=\"font-size:1em\"> 12.12.2020 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data Load and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.3\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: 'data.table'\n",
      "\n",
      "The following objects are masked from 'package:dplyr':\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "Warning message:\n",
      "\"package 'glue' was built under R version 3.6.3\"\n",
      "Attaching package: 'glue'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    collapse\n",
      "\n",
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'gridExtra' was built under R version 3.6.3\"\n",
      "Attaching package: 'gridExtra'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "Warning message:\n",
      "\"package 'tidyr' was built under R version 3.6.3\""
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "require(dplyr, quietly = TRUE)\n",
    "require(data.table, quietly = TRUE)\n",
    "require(glue, quietly = TRUE)\n",
    "require(ggplot2, quietly = TRUE)\n",
    "require(scatterplot3d, quietly = TRUE)\n",
    "require(gridExtra, quietly = TRUE)\n",
    "require(tidyr, quietly = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Dataload\n",
    "axes <- c(\"X\",\"Y\",\"Z\")\n",
    "df <- list(); dftest <- list()\n",
    "\n",
    "for (i in axes){\n",
    "    df[[length(df) + 1]] <- fread(glue(\"Data/Train/uWaveGestureLibrary_{i}_TRAIN\"))\n",
    "    dftest[[length(dftest) + 1]] <- fread(glue(\"Data/Test/uWaveGestureLibrary_{i}_TEST\"))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for (i in 1:3){\n",
    "    ax = axes[i]\n",
    "\n",
    "    #Train Data Preparation\n",
    "    \n",
    "    df[[i]][,\"Observation\"] = 1:dim(df[[i]])[1]\n",
    "    setcolorder(df[[i]], c(length(df[[i]]),1,2:(length(df[[i]])-1)))\n",
    "    #New Colnames\n",
    "    newcolnames <- c(\"Observation\",\"Class\",1:(length(df[[1]])-2))\n",
    "    newcolnames <- c(\"Observation\",\"Class\",paste(glue(\"{ax}\"),\"_t\",newcolnames[3:length(newcolnames)],sep=\"\")) \n",
    "    colnames(df[[i]]) = newcolnames\n",
    "    \n",
    "    #Test Data Preparation\n",
    "    \n",
    "    dftest[[i]][,\"Observation\"] = 1:dim(dftest[[i]])[1]\n",
    "    setcolorder(dftest[[i]], c(length(dftest[[i]]),1,2:(length(dftest[[i]])-1)))\n",
    "    #New Colnames\n",
    "    newcolnames <- c(\"Observation\",\"Class\",1:(length(dftest[[1]])-2))\n",
    "    newcolnames <- c(\"Observation\",\"Class\",paste(glue(\"{ax}\"),\"_t\",newcolnames[3:length(newcolnames)],sep=\"\"))\n",
    "    colnames(dftest[[i]]) = newcolnames\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merging Tables\n",
    "\n",
    "dfmerged <- merge(df[[1]], df[[2]], by = c(\"Observation\", \"Class\"), all=TRUE)\n",
    "dfmerged <- merge(dfmerged, df[[3]], by = c(\"Observation\", \"Class\"), all=TRUE)\n",
    "\n",
    "dftestmerged <- merge(dftest[[1]], dftest[[2]], by = c(\"Observation\", \"Class\"), all=TRUE)\n",
    "dftestmerged <- merge(dftestmerged, dftest[[3]], by = c(\"Observation\", \"Class\"), all=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     row col"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     row col"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Missing Data Check\n",
    "which(is.na(dfmerged),TRUE);which(is.na(dftestmerged),TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Source data consists of time series observations in three axes: X, Y and Z. Each row of the final data table corresponds to a serie and distances betweens these series (observations) will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Observation</th><th scope=col>Class</th><th scope=col>X_t1</th><th scope=col>X_t2</th><th scope=col>X_t3</th><th scope=col>X_t4</th><th scope=col>X_t5</th><th scope=col>X_t6</th><th scope=col>X_t7</th><th scope=col>X_t8</th><th scope=col>...</th><th scope=col>Z_t306</th><th scope=col>Z_t307</th><th scope=col>Z_t308</th><th scope=col>Z_t309</th><th scope=col>Z_t310</th><th scope=col>Z_t311</th><th scope=col>Z_t312</th><th scope=col>Z_t313</th><th scope=col>Z_t314</th><th scope=col>Z_t315</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1           </td><td>6           </td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>-0.304243210</td><td>...         </td><td> 0.5232168  </td><td> 0.5139944  </td><td> 0.50348075 </td><td> 0.49296714 </td><td> 0.47452222 </td><td> 0.4560773  </td><td> 0.4376324  </td><td> 0.4191875  </td><td> 0.4007426  </td><td> 0.3822976  </td></tr>\n",
       "\t<tr><td>2           </td><td>5           </td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td> 1.627311100</td><td>...         </td><td>-0.4270104  </td><td>-0.4270104  </td><td>-0.42701043 </td><td>-0.42717222 </td><td>-0.42877307 </td><td>-0.4407199  </td><td>-0.4526667  </td><td>-0.4646135  </td><td>-0.4765603  </td><td>-0.4885071  </td></tr>\n",
       "\t<tr><td>3           </td><td>5           </td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td> 0.661276530</td><td>...         </td><td>-0.8627172  </td><td>-0.8627172  </td><td>-0.86271720 </td><td>-0.86271720 </td><td>-0.86271720 </td><td>-0.8627172  </td><td>-0.8627172  </td><td>-0.8627172  </td><td>-0.8627172  </td><td>-0.8627172  </td></tr>\n",
       "\t<tr><td>4           </td><td>3           </td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td> 0.005184784</td><td>...         </td><td>-0.1873845  </td><td>-0.1235489  </td><td>-0.05587047 </td><td> 0.01180812 </td><td> 0.07948656 </td><td> 0.1570561  </td><td> 0.2537396  </td><td> 0.4455027  </td><td> 0.6485381  </td><td> 0.8515735  </td></tr>\n",
       "\t<tr><td>5           </td><td>4           </td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td> 1.286197800</td><td>...         </td><td> 1.8674725  </td><td> 1.8343190  </td><td> 1.75599960 </td><td> 1.63858220 </td><td> 1.52116390 </td><td> 1.4532661  </td><td> 1.5152189  </td><td> 1.6326367  </td><td> 1.7500543  </td><td> 1.8674725  </td></tr>\n",
       "\t<tr><td>6           </td><td>8           </td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>-0.479252460</td><td>...         </td><td> 0.6979770  </td><td> 0.6654623  </td><td> 0.63294758 </td><td> 0.60043289 </td><td> 0.55859021 </td><td> 0.5167475  </td><td> 0.4679755  </td><td> 0.4192035  </td><td> 0.3704314  </td><td> 0.3216594  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " Observation & Class & X\\_t1 & X\\_t2 & X\\_t3 & X\\_t4 & X\\_t5 & X\\_t6 & X\\_t7 & X\\_t8 & ... & Z\\_t306 & Z\\_t307 & Z\\_t308 & Z\\_t309 & Z\\_t310 & Z\\_t311 & Z\\_t312 & Z\\_t313 & Z\\_t314 & Z\\_t315\\\\\n",
       "\\hline\n",
       "\t 1            & 6            & -0.304243210 & -0.304243210 & -0.304243210 & -0.304243210 & -0.304243210 & -0.304243210 & -0.304243210 & -0.304243210 & ...          &  0.5232168   &  0.5139944   &  0.50348075  &  0.49296714  &  0.47452222  &  0.4560773   &  0.4376324   &  0.4191875   &  0.4007426   &  0.3822976  \\\\\n",
       "\t 2            & 5            &  1.627311100 &  1.627311100 &  1.627311100 &  1.627311100 &  1.627311100 &  1.627311100 &  1.627311100 &  1.627311100 & ...          & -0.4270104   & -0.4270104   & -0.42701043  & -0.42717222  & -0.42877307  & -0.4407199   & -0.4526667   & -0.4646135   & -0.4765603   & -0.4885071  \\\\\n",
       "\t 3            & 5            &  0.661276530 &  0.661276530 &  0.661276530 &  0.661276530 &  0.661276530 &  0.661276530 &  0.661276530 &  0.661276530 & ...          & -0.8627172   & -0.8627172   & -0.86271720  & -0.86271720  & -0.86271720  & -0.8627172   & -0.8627172   & -0.8627172   & -0.8627172   & -0.8627172  \\\\\n",
       "\t 4            & 3            &  0.005184784 &  0.005184784 &  0.005184784 &  0.005184784 &  0.005184784 &  0.005184784 &  0.005184784 &  0.005184784 & ...          & -0.1873845   & -0.1235489   & -0.05587047  &  0.01180812  &  0.07948656  &  0.1570561   &  0.2537396   &  0.4455027   &  0.6485381   &  0.8515735  \\\\\n",
       "\t 5            & 4            &  1.286197800 &  1.286197800 &  1.286197800 &  1.286197800 &  1.286197800 &  1.286197800 &  1.286197800 &  1.286197800 & ...          &  1.8674725   &  1.8343190   &  1.75599960  &  1.63858220  &  1.52116390  &  1.4532661   &  1.5152189   &  1.6326367   &  1.7500543   &  1.8674725  \\\\\n",
       "\t 6            & 8            & -0.479252460 & -0.479252460 & -0.479252460 & -0.479252460 & -0.479252460 & -0.479252460 & -0.479252460 & -0.479252460 & ...          &  0.6979770   &  0.6654623   &  0.63294758  &  0.60043289  &  0.55859021  &  0.5167475   &  0.4679755   &  0.4192035   &  0.3704314   &  0.3216594  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Observation | Class | X_t1 | X_t2 | X_t3 | X_t4 | X_t5 | X_t6 | X_t7 | X_t8 | ... | Z_t306 | Z_t307 | Z_t308 | Z_t309 | Z_t310 | Z_t311 | Z_t312 | Z_t313 | Z_t314 | Z_t315 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1            | 6            | -0.304243210 | -0.304243210 | -0.304243210 | -0.304243210 | -0.304243210 | -0.304243210 | -0.304243210 | -0.304243210 | ...          |  0.5232168   |  0.5139944   |  0.50348075  |  0.49296714  |  0.47452222  |  0.4560773   |  0.4376324   |  0.4191875   |  0.4007426   |  0.3822976   |\n",
       "| 2            | 5            |  1.627311100 |  1.627311100 |  1.627311100 |  1.627311100 |  1.627311100 |  1.627311100 |  1.627311100 |  1.627311100 | ...          | -0.4270104   | -0.4270104   | -0.42701043  | -0.42717222  | -0.42877307  | -0.4407199   | -0.4526667   | -0.4646135   | -0.4765603   | -0.4885071   |\n",
       "| 3            | 5            |  0.661276530 |  0.661276530 |  0.661276530 |  0.661276530 |  0.661276530 |  0.661276530 |  0.661276530 |  0.661276530 | ...          | -0.8627172   | -0.8627172   | -0.86271720  | -0.86271720  | -0.86271720  | -0.8627172   | -0.8627172   | -0.8627172   | -0.8627172   | -0.8627172   |\n",
       "| 4            | 3            |  0.005184784 |  0.005184784 |  0.005184784 |  0.005184784 |  0.005184784 |  0.005184784 |  0.005184784 |  0.005184784 | ...          | -0.1873845   | -0.1235489   | -0.05587047  |  0.01180812  |  0.07948656  |  0.1570561   |  0.2537396   |  0.4455027   |  0.6485381   |  0.8515735   |\n",
       "| 5            | 4            |  1.286197800 |  1.286197800 |  1.286197800 |  1.286197800 |  1.286197800 |  1.286197800 |  1.286197800 |  1.286197800 | ...          |  1.8674725   |  1.8343190   |  1.75599960  |  1.63858220  |  1.52116390  |  1.4532661   |  1.5152189   |  1.6326367   |  1.7500543   |  1.8674725   |\n",
       "| 6            | 8            | -0.479252460 | -0.479252460 | -0.479252460 | -0.479252460 | -0.479252460 | -0.479252460 | -0.479252460 | -0.479252460 | ...          |  0.6979770   |  0.6654623   |  0.63294758  |  0.60043289  |  0.55859021  |  0.5167475   |  0.4679755   |  0.4192035   |  0.3704314   |  0.3216594   |\n",
       "\n"
      ],
      "text/plain": [
       "  Observation Class X_t1         X_t2         X_t3         X_t4        \n",
       "1 1           6     -0.304243210 -0.304243210 -0.304243210 -0.304243210\n",
       "2 2           5      1.627311100  1.627311100  1.627311100  1.627311100\n",
       "3 3           5      0.661276530  0.661276530  0.661276530  0.661276530\n",
       "4 4           3      0.005184784  0.005184784  0.005184784  0.005184784\n",
       "5 5           4      1.286197800  1.286197800  1.286197800  1.286197800\n",
       "6 6           8     -0.479252460 -0.479252460 -0.479252460 -0.479252460\n",
       "  X_t5         X_t6         X_t7         X_t8         ... Z_t306     Z_t307    \n",
       "1 -0.304243210 -0.304243210 -0.304243210 -0.304243210 ...  0.5232168  0.5139944\n",
       "2  1.627311100  1.627311100  1.627311100  1.627311100 ... -0.4270104 -0.4270104\n",
       "3  0.661276530  0.661276530  0.661276530  0.661276530 ... -0.8627172 -0.8627172\n",
       "4  0.005184784  0.005184784  0.005184784  0.005184784 ... -0.1873845 -0.1235489\n",
       "5  1.286197800  1.286197800  1.286197800  1.286197800 ...  1.8674725  1.8343190\n",
       "6 -0.479252460 -0.479252460 -0.479252460 -0.479252460 ...  0.6979770  0.6654623\n",
       "  Z_t308      Z_t309      Z_t310      Z_t311     Z_t312     Z_t313    \n",
       "1  0.50348075  0.49296714  0.47452222  0.4560773  0.4376324  0.4191875\n",
       "2 -0.42701043 -0.42717222 -0.42877307 -0.4407199 -0.4526667 -0.4646135\n",
       "3 -0.86271720 -0.86271720 -0.86271720 -0.8627172 -0.8627172 -0.8627172\n",
       "4 -0.05587047  0.01180812  0.07948656  0.1570561  0.2537396  0.4455027\n",
       "5  1.75599960  1.63858220  1.52116390  1.4532661  1.5152189  1.6326367\n",
       "6  0.63294758  0.60043289  0.55859021  0.5167475  0.4679755  0.4192035\n",
       "  Z_t314     Z_t315    \n",
       "1  0.4007426  0.3822976\n",
       "2 -0.4765603 -0.4885071\n",
       "3 -0.8627172 -0.8627172\n",
       "4  0.6485381  0.8515735\n",
       "5  1.7500543  1.8674725\n",
       "6  0.3704314  0.3216594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dfmerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task a: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before applying k-NN algorithm, distance measures of time series observations are calculated. Two distance measures are adapted:  \n",
    "- Euclidian:  $ d_{ij} = \\sum_{k = 1}^p{(x_{ik} - x_{jk})^2}  $\n",
    "- Manhattan:     $ d_{ij} = \\sum_{k = 1}^p {\\lvert x_{ik} - x_{jk} \\rvert }  $  \n",
    "\n",
    "Where i and j are observations and p is the number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kfoldsplit <- function(data,k,order){\n",
    "    order <- (order-1) %% k + 1\n",
    "    n <- dim(data)[1]\n",
    "    size <- ceiling(n/k)\n",
    "    idx <- ((order-1)*size + 1):(min(order*size,n))\n",
    "    \n",
    "    train <- data[-idx]\n",
    "    valid <- data[idx]\n",
    "    res <- list()\n",
    "    res[[1]] <- train\n",
    "    res[[2]] <- valid\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getmode <- function(v) {\n",
    "    v <- as.vector(v)\n",
    "   tbl <- table(v)\n",
    "   return(names(which.max(tbl)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid = 1:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knnfit <- function(df, foldnum = 10, grid = 1:2)\n",
    "{\n",
    "    start <- Sys.time()\n",
    "    AccEuc <- NULL; AccMan <- NULL; allpredseuc <- NULL; allpredsman <- NULL\n",
    "    \n",
    "    for(K in grid){\n",
    "        cat(\"K= \",K) \n",
    "        cvAccEuc <- NULL; cvAccMan <- NULL; cvpredseuc <- NULL; cvpredsman <- NULL\n",
    "        \n",
    "        for (fold in 1:foldnum){\n",
    "            cat(\"fold %d\",fold)\n",
    "            \n",
    "            split = kfoldsplit(df,foldnum,fold)\n",
    "            train <- split[[1]][,-c(1,2)]\n",
    "            valid <- split[[2]][,-c(1,2)]\n",
    "            trainclass <- split[[1]][,2]\n",
    "            validclass <- split[[2]][,2]\n",
    "            combined=rbind(valid,train)\n",
    "            \n",
    "            eucdistcombined = as.matrix(dist(combined, method = \"euclidian\")) # Euclidian Distance\n",
    "            mandistcombined = as.matrix(dist(combined, method = \"manhattan\")) # Manhattan Distance\n",
    "            \n",
    "            lnvalid = dim(valid)[1]; lntrain = dim(train)[1]; lnall = lnvalid + lntrain\n",
    "            \n",
    "            eucdistcombined = eucdistcombined[1:lnvalid,(lnvalid+1):lnall]\n",
    "            mandistcombined = mandistcombined[1:lnvalid,(lnvalid+1):lnall]\n",
    "            \n",
    "            neighbors_euc = t(apply(eucdistcombined, 1, order))\n",
    "            neighbors_man = t(apply(mandistcombined, 1, order))\n",
    "            \n",
    "            idxeuc = t(apply(neighbors_euc, 1, function(x) x[1:K] ) )\n",
    "            idxman = t(apply(neighbors_man, 1, function(x) x[1:K] ) )\n",
    "            \n",
    "            predseuc = apply(idxeuc, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "            predsman = apply(idxman, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "                         \n",
    "            cvAccEuc <- c( cvAccEuc, sum(validclass == predseuc)/dim(validclass)[1] )\n",
    "            cvAccMan <- c( cvAccMan, sum(validclass == predsman)/dim(validclass)[1] )\n",
    "        }                 \n",
    "        AccEuc <- rbind(AccEuc, t(c(K,cvAccEuc))); AccMan <- rbind(AccMan, t(c(K,cvAccMan)))\n",
    "    }\n",
    "    str(Sys.time() - start)\n",
    "    res = list();\n",
    "    res[[ length(res) + 1]] = AccEuc; res[[ length(res) + 1]] = AccMan\n",
    "    return(res)\n",
    "}\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fit <- knnfit(dfmerged, 10, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meanAccEuc <- cbind(fit[[1]][,1],apply(fit[[1]][,-1],1,mean))\n",
    "meanAccMan <- cbind(fit[[2]][,1],apply(fit[[2]][,-1],1,mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Accuracy is calculated as: $$ \\frac{True Positive + True Negative}{ Total Observations}$$and error rate is calculated as: $$ \\frac{False Positive + False Negative}{Total Observations} = 1 - Accuracy$$   \n",
    "Hence, to minimize error rate, we can maximize accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Euclidian Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQJAAAQQJEECQAAH/AAqqwDg2BrhQAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Euclidian Distance\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(meanAccEuc[-1,1],meanAccEuc[-1,2],type = 'l', ylab=\"Accuracy\",xlab=\"K\", main = \"Euclidian Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanAccEuc[which.max(meanAccEuc[,2]),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.945348837209302"
      ],
      "text/latex": [
       "0.945348837209302"
      ],
      "text/markdown": [
       "0.945348837209302"
      ],
      "text/plain": [
       "[1] 0.9453488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanAccEuc[which.max(meanAccEuc[,2]),2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Optimum K value is **3** for **Euclidian Distance**. Accuracy value for K=3 is **94.5349%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Manhattan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQABBAgQQJEAAQQIEECRAwD+ZmaoPh8PxlgAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Manhattan Distance\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(meanAccMan[-1,1],meanAccMan[-1,2],type = 'l', ylab=\"Accuracy\",xlab=\"K\", main = \"Manhattan Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanAccMan[which.max(meanAccMan[,2]),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.955503875968992"
      ],
      "text/latex": [
       "0.955503875968992"
      ],
      "text/markdown": [
       "0.955503875968992"
      ],
      "text/plain": [
       "[1] 0.9555039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanAccMan[which.max(meanAccMan[,2]),2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Optimum K value is same for **Manhattan Distance** as well:  **3**. The accuracy value is higher from the previous approach: **95.5504%** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task b: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knntest <- function(traindf, testdf, K)\n",
    "{\n",
    "    start <- Sys.time()\n",
    "    AccEuc <- NULL; AccMan <- NULL; allpredseuc <- NULL; allpredsman <- NULL\n",
    "\n",
    "    train <- traindf[,-c(1,2)]\n",
    "    test <- testdf[,-c(1,2)]\n",
    "    trainclass <- traindf[,2]\n",
    "    testclass <- testdf[,2]\n",
    "    combined=rbind(test,train)\n",
    "    \n",
    "    eucdistcombined = as.matrix(dist(combined, method = \"euclidian\")) # Euclidian Distance\n",
    "    mandistcombined = as.matrix(dist(combined, method = \"manhattan\")) # Manhattan Distance\n",
    "    \n",
    "    lntest = dim(test)[1]; lntrain = dim(train)[1]; lnall = lntest + lntrain\n",
    "    \n",
    "    eucdistcombined = eucdistcombined[1:lntest,(lntest+1):lnall]\n",
    "    mandistcombined = mandistcombined[1:lntest,(lntest+1):lnall]\n",
    "    \n",
    "    neighbors_euc = t(apply(eucdistcombined, 1, order))\n",
    "    neighbors_man = t(apply(mandistcombined, 1, order))\n",
    "    \n",
    "    idxeuc = t(apply(neighbors_euc, 1, function(x) x[1:K] ) )\n",
    "    idxman = t(apply(neighbors_man, 1, function(x) x[1:K] ) )\n",
    "    \n",
    "    predseuc = apply(idxeuc, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "    predsman = apply(idxman, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "                 \n",
    "    AccEuc <- sum(testclass == predseuc)/dim(testclass)[1]\n",
    "    AccMan <- sum(testclass == predsman)/dim(testclass)[1]\n",
    "    \n",
    "    res = list();\n",
    "    res[[ length(res) + 1]] = predseuc; res[[ length(res) + 1]] = AccEuc\n",
    "    res[[ length(res) + 1]] = predsman; res[[ length(res) + 1]] = AccMan\n",
    "    str(Sys.time() - start)\n",
    "    return(res)\n",
    "}\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'difftime' num 2.20502690076828\n",
      " - attr(*, \"units\")= chr \"mins\"\n"
     ]
    }
   ],
   "source": [
    "preds <- knntest(dfmerged, dftestmerged, K = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The algorithm took **2.21 minutes** to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>4</dd>\n",
       "</dl>\n",
       "</li>\n",
       "\t<li>0.943886097152429</li>\n",
       "\t<li><dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>4</dd>\n",
       "</dl>\n",
       "</li>\n",
       "\t<li>0.950027917364601</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{description*}\n",
       "\\item[1] 5\n",
       "\\item[2] 1\n",
       "\\item[3] 4\n",
       "\\item[4] 4\n",
       "\\item[5] 5\n",
       "\\item[6] 4\n",
       "\\end{description*}\n",
       "\n",
       "\\item 0.943886097152429\n",
       "\\item \\begin{description*}\n",
       "\\item[1] 5\n",
       "\\item[2] 1\n",
       "\\item[3] 4\n",
       "\\item[4] 4\n",
       "\\item[5] 5\n",
       "\\item[6] 4\n",
       "\\end{description*}\n",
       "\n",
       "\\item 0.950027917364601\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       ":   52\n",
       ":   13\n",
       ":   44\n",
       ":   45\n",
       ":   56\n",
       ":   4\n",
       "\n",
       "\n",
       "2. 0.943886097152429\n",
       "3. 1\n",
       ":   52\n",
       ":   13\n",
       ":   44\n",
       ":   45\n",
       ":   56\n",
       ":   4\n",
       "\n",
       "\n",
       "4. 0.950027917364601\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "1 2 3 4 5 6 \n",
       "5 1 4 4 5 4 \n",
       "\n",
       "[[2]]\n",
       "[1] 0.9438861\n",
       "\n",
       "[[3]]\n",
       "1 2 3 4 5 6 \n",
       "5 1 4 4 5 4 \n",
       "\n",
       "[[4]]\n",
       "[1] 0.9500279\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(preds,head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Euclidian Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUCLIDIAN DISTANCE CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             Predictions\n",
       "Actuals.Class   1   2   3   4   5   6   7   8\n",
       "            1 431   0   0   2   0   4   0   0\n",
       "            2   1 449   0   0   0   0   2   0\n",
       "            3   2   0 413   0  15  20   4   0\n",
       "            4   7   0   0 370  60   6   0   7\n",
       "            5   3   0   6   1 422   1   0   0\n",
       "            6   6   0   7  15  28 392   1   0\n",
       "            7   0   0   1   0   0   0 446   0\n",
       "            8   0   0   0   1   1   0   0 458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  94.38861 %"
     ]
    }
   ],
   "source": [
    "cat(\"EUCLIDIAN DISTANCE CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = dftestmerged[,2] ,Predictions = preds[[1]]  ) )\n",
    "cat(\"Accuracy is: \",preds[[2]]*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Manhattan Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANHATTAN DISTANCE CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             Predictions\n",
       "Actuals.Class   1   2   3   4   5   6   7   8\n",
       "            1 432   0   0   2   0   3   0   0\n",
       "            2   1 451   0   0   0   0   0   0\n",
       "            3   3   0 420   0  11  16   4   0\n",
       "            4   3   0   0 385  48   7   0   7\n",
       "            5   3   0   5   2 422   1   0   0\n",
       "            6  10   0   4  16  25 394   0   0\n",
       "            7   0   0   5   0   0   0 442   0\n",
       "            8   0   0   0   2   1   0   0 457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  95.00279 %"
     ]
    }
   ],
   "source": [
    "cat(\"MANHATTAN DISTANCE CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = dftestmerged[,2] ,Predictions = preds[[3]]  ) )\n",
    "cat(\"Accuracy is: \",preds[[4]]*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task c: Weighted Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we calculate **Euclidian** distance matrix using all axes, in fact, we calculate **quadratic mean** of Euclidian distances based on all axes seperately. Quadratic mean is always greater than arithmetic mean which means this approach calculates distance closer to higher values. As for Manhattan distance, calculating overall distance or arihmetic mean of axis based distances yields the same result.\n",
    "\n",
    "If distances based on all axes are equally important, weighted approach with equal weights would be more sensible to calculate distances. Better accuracy results in both crass-validation and test sets also solidify this assumption. Hence, as an alternative approach, **arithmetic mean of axis based Euclidian distances** can be used.\n",
    "\n",
    "One other approach could be deciding importance of axis based distances looking at absolute correlation values. Sum of correlation values between instance classes and axis observations can be decided as weight of each axis and then the **correlation weighted average of axis based Euclidian/Manhattan distances** can be used as total distance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculting correlation weights (-1 to remove observation ID's)\n",
    "wx = sum(cor(dfmerged[,-1])[1,2:316])\n",
    "wy = sum(cor(dfmerged[,-1])[1,317:631])\n",
    "wz = sum(cor(dfmerged[,-1])[1,632:946])\n",
    "wtot = wx + wy + wz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.602856214940997"
      ],
      "text/latex": [
       "0.602856214940997"
      ],
      "text/markdown": [
       "0.602856214940997"
      ],
      "text/plain": [
       "[1] 0.6028562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.236212826175685"
      ],
      "text/latex": [
       "0.236212826175685"
      ],
      "text/markdown": [
       "0.236212826175685"
      ],
      "text/plain": [
       "[1] 0.2362128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.160930958883318"
      ],
      "text/latex": [
       "0.160930958883318"
      ],
      "text/markdown": [
       "0.160930958883318"
      ],
      "text/plain": [
       "[1] 0.160931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wx = wx/wtot; wx\n",
    "wy = wy/wtot; wy\n",
    "wz = wz/wtot; wz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "X axis has the highest effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weightedknn <- function(dflist, dftestlist, wx, wy, wz, K)\n",
    "{\n",
    "    start <- Sys.time()\n",
    "    AccEuc <- NULL; AccMan <- NULL; allpredseuc <- NULL; allpredsman <- NULL\n",
    "\n",
    "    trainx <- dflist[[1]][,-c(1,2)]\n",
    "    trainy <- dflist[[2]][,-c(1,2)]\n",
    "    trainz <- dflist[[3]][,-c(1,2)]\n",
    "    trainclass <- dflist[[1]][,2]\n",
    "    \n",
    "    testx <- dftestlist[[1]][,-c(1,2)]\n",
    "    testy <- dftestlist[[2]][,-c(1,2)]\n",
    "    testz <- dftestlist[[3]][,-c(1,2)]\n",
    "    testclass <- dftestlist[[1]][,2]\n",
    "\n",
    "    combinedx=rbind(testx,trainx)\n",
    "    combinedy=rbind(testy,trainy)\n",
    "    combinedz=rbind(testz,trainz)\n",
    "    \n",
    "    eucdistcombinedx = as.matrix(dist(combinedx, method = \"euclidian\"))\n",
    "    mandistcombinedx = as.matrix(dist(combinedx, method = \"manhattan\"))\n",
    "    eucdistcombinedy = as.matrix(dist(combinedy, method = \"euclidian\"))\n",
    "    mandistcombinedy = as.matrix(dist(combinedy, method = \"manhattan\"))\n",
    "    eucdistcombinedz = as.matrix(dist(combinedz, method = \"euclidian\"))\n",
    "    mandistcombinedz = as.matrix(dist(combinedz, method = \"manhattan\"))\n",
    "    eucdistcombined = wx*eucdistcombinedx + wy*eucdistcombinedy + wz*eucdistcombinedz # Euclidian Distance\n",
    "    mandistcombined = wx*mandistcombinedx + wy*mandistcombinedy + wz*mandistcombinedz # Manhattan Distance\n",
    "    \n",
    "    lntest = dim(testx)[1]; lntrain = dim(trainx)[1]; lnall = lntest + lntrain\n",
    "    \n",
    "    eucdistcombined = eucdistcombined[1:lntest,(lntest+1):lnall]\n",
    "    mandistcombined = mandistcombined[1:lntest,(lntest+1):lnall]\n",
    "    \n",
    "    neighbors_euc = t(apply(eucdistcombined, 1, order))\n",
    "    neighbors_man = t(apply(mandistcombined, 1, order))\n",
    "    \n",
    "    idxeuc = t(apply(neighbors_euc, 1, function(x) x[1:K] ) )\n",
    "    idxman = t(apply(neighbors_man, 1, function(x) x[1:K] ) )\n",
    "    \n",
    "    predseuc = apply(idxeuc, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "    predsman = apply(idxman, 1, function(x) as.numeric(getmode( trainclass[as.vector(x),1] )) )\n",
    "                 \n",
    "    AccEuc <- sum(testclass == predseuc)/dim(testclass)[1]\n",
    "    AccMan <- sum(testclass == predsman)/dim(testclass)[1]\n",
    "    \n",
    "    res = list();\n",
    "    res[[ length(res) + 1]] = predseuc; res[[ length(res) + 1]] = AccEuc\n",
    "    res[[ length(res) + 1]] = predsman; res[[ length(res) + 1]] = AccMan\n",
    "    str(Sys.time() - start)\n",
    "    return(res)\n",
    "}\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'difftime' num 1.21562515099843\n",
      " - attr(*, \"units\")= chr \"mins\"\n"
     ]
    }
   ],
   "source": [
    "predsweighted <- weightedknn(df,dftest,wx,wy,wz,K=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Optimal K value is assumed to be 3 for this approach as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>4</dd>\n",
       "</dl>\n",
       "</li>\n",
       "\t<li>0.94751535455053</li>\n",
       "\t<li><dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>4</dd>\n",
       "</dl>\n",
       "</li>\n",
       "\t<li>0.946398659966499</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{description*}\n",
       "\\item[1] 5\n",
       "\\item[2] 1\n",
       "\\item[3] 4\n",
       "\\item[4] 4\n",
       "\\item[5] 5\n",
       "\\item[6] 4\n",
       "\\end{description*}\n",
       "\n",
       "\\item 0.94751535455053\n",
       "\\item \\begin{description*}\n",
       "\\item[1] 4\n",
       "\\item[2] 1\n",
       "\\item[3] 4\n",
       "\\item[4] 4\n",
       "\\item[5] 5\n",
       "\\item[6] 4\n",
       "\\end{description*}\n",
       "\n",
       "\\item 0.946398659966499\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       ":   52\n",
       ":   13\n",
       ":   44\n",
       ":   45\n",
       ":   56\n",
       ":   4\n",
       "\n",
       "\n",
       "2. 0.94751535455053\n",
       "3. 1\n",
       ":   42\n",
       ":   13\n",
       ":   44\n",
       ":   45\n",
       ":   56\n",
       ":   4\n",
       "\n",
       "\n",
       "4. 0.946398659966499\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "1 2 3 4 5 6 \n",
       "5 1 4 4 5 4 \n",
       "\n",
       "[[2]]\n",
       "[1] 0.9475154\n",
       "\n",
       "[[3]]\n",
       "1 2 3 4 5 6 \n",
       "4 1 4 4 5 4 \n",
       "\n",
       "[[4]]\n",
       "[1] 0.9463987\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predsweighted,head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Accuracy scores came out to be worse. Thus, the assumptions did not lead to better results. Hyper-parameter tuning with cross-validation is necessary. Further work is needed to test this approaches however, results so far are not in favor of this new approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Load and Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 100  96\n"
     ]
    }
   ],
   "source": [
    "fname='Data/Train/ecgTRAIN' # data path\n",
    "traindata <- as.matrix(read.table(fname))  # read data into a matrix named traindata\n",
    "#first column is the class variable\n",
    "trainclass=traindata[,1] # takes -1 and 1\n",
    "#drop first column\n",
    "traindata=traindata[,2:ncol(traindata)]\n",
    "print(dim(traindata)) #shows that there 100 series (rows) of length 96 time units (columns)\n",
    "\n",
    "tlength=ncol(traindata)\n",
    "noftimeseries=nrow(traindata)\n",
    "\n",
    "#read test data\n",
    "fname='Data/Test/ecgTEST' # data path\n",
    "testdata <- as.matrix(read.table(fname))  # read data into a matrix named traindata\n",
    "#first column is the class variable\n",
    "testclass=testdata[,1] # takes -1 and 1\n",
    "#drop first column\n",
    "testdata=testdata[,2:ncol(testdata)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th><th scope=col>...</th><th scope=col>V88</th><th scope=col>V89</th><th scope=col>V90</th><th scope=col>V91</th><th scope=col>V92</th><th scope=col>V93</th><th scope=col>V94</th><th scope=col>V95</th><th scope=col>V96</th><th scope=col>V97</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.5020555  </td><td>0.5421626  </td><td>0.7223835  </td><td>1.4288852  </td><td>2.1365158  </td><td> 2.2811490 </td><td> 1.93627370</td><td> 1.4688900 </td><td> 1.0088451 </td><td> 0.3802822 </td><td>...        </td><td> 0.93104294</td><td> 0.6102984 </td><td> 0.6388943 </td><td> 0.6846786 </td><td> 0.58323764</td><td> 0.6405217 </td><td> 0.70858515</td><td> 0.70501088</td><td> 0.7138155 </td><td> 0.4337646 </td></tr>\n",
       "\t<tr><td>0.1474864  </td><td>0.8032087  </td><td>0.3671757  </td><td>0.2435429  </td><td>0.0266927  </td><td>-0.2737281 </td><td> 0.09667076</td><td>-0.7461207 </td><td>-1.6064626 </td><td>-1.1771292 </td><td>...        </td><td>-0.53231711</td><td>-0.3993053 </td><td> 0.1758674 </td><td> 1.1097011 </td><td> 2.43373800</td><td> 2.7296122 </td><td> 1.73275310</td><td> 0.03691512</td><td>-1.2624415 </td><td>-0.2074816 </td></tr>\n",
       "\t<tr><td>0.3166462  </td><td>0.2431991  </td><td>0.3704714  </td><td>1.0637381  </td><td>1.6781871  </td><td> 1.7595575 </td><td> 1.69771720</td><td> 1.6121590 </td><td> 1.1681877 </td><td> 0.4999570 </td><td>...        </td><td> 0.76422904</td><td> 0.6106215 </td><td> 0.5529003 </td><td> 0.5667861 </td><td> 0.60400236</td><td> 0.7770678 </td><td> 0.81234542</td><td> 0.74884814</td><td> 0.8180420 </td><td> 0.5393470 </td></tr>\n",
       "\t<tr><td>1.1688741  </td><td>2.0759008  </td><td>1.7601405  </td><td>1.6064459  </td><td>1.9490456  </td><td> 1.3028421 </td><td> 0.45933154</td><td> 0.5164121 </td><td> 0.8521795 </td><td> 0.9892272 </td><td>...        </td><td> 0.41900645</td><td> 0.7238875 </td><td> 1.3239469 </td><td> 2.1364876 </td><td> 1.74659650</td><td> 1.4702205 </td><td> 1.89351230</td><td> 1.25694930</td><td> 0.8004066 </td><td> 0.7315398 </td></tr>\n",
       "\t<tr><td>0.6479446  </td><td>0.7512234  </td><td>2.6337955  </td><td>3.4525696  </td><td>2.1161707  </td><td> 0.5200183 </td><td>-0.18861376</td><td> 0.7799909 </td><td> 0.9328146 </td><td> 0.7006434 </td><td>...        </td><td>-0.09793465</td><td>-0.1368191 </td><td>-0.3400925 </td><td>-0.0895146 </td><td>-0.08037838</td><td>-0.1925682 </td><td>-0.30459103</td><td>-0.45431295</td><td> 0.3141666 </td><td> 0.5815342 </td></tr>\n",
       "\t<tr><td>0.4035074  </td><td>1.2771034  </td><td>2.5078283  </td><td>1.2957095  </td><td>1.4491787  </td><td> 0.4728490 </td><td>-1.39258560</td><td>-0.6452687 </td><td> 0.4306412 </td><td> 0.1320061 </td><td>...        </td><td> 0.37532545</td><td> 0.2769523 </td><td> 0.2249676 </td><td> 0.1585749 </td><td> 0.40711823</td><td> 0.5383992 </td><td>-0.02776744</td><td> 0.20283211</td><td> 0.3459054 </td><td> 0.3381487 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11 & ... & V88 & V89 & V90 & V91 & V92 & V93 & V94 & V95 & V96 & V97\\\\\n",
       "\\hline\n",
       "\t 0.5020555   & 0.5421626   & 0.7223835   & 1.4288852   & 2.1365158   &  2.2811490  &  1.93627370 &  1.4688900  &  1.0088451  &  0.3802822  & ...         &  0.93104294 &  0.6102984  &  0.6388943  &  0.6846786  &  0.58323764 &  0.6405217  &  0.70858515 &  0.70501088 &  0.7138155  &  0.4337646 \\\\\n",
       "\t 0.1474864   & 0.8032087   & 0.3671757   & 0.2435429   & 0.0266927   & -0.2737281  &  0.09667076 & -0.7461207  & -1.6064626  & -1.1771292  & ...         & -0.53231711 & -0.3993053  &  0.1758674  &  1.1097011  &  2.43373800 &  2.7296122  &  1.73275310 &  0.03691512 & -1.2624415  & -0.2074816 \\\\\n",
       "\t 0.3166462   & 0.2431991   & 0.3704714   & 1.0637381   & 1.6781871   &  1.7595575  &  1.69771720 &  1.6121590  &  1.1681877  &  0.4999570  & ...         &  0.76422904 &  0.6106215  &  0.5529003  &  0.5667861  &  0.60400236 &  0.7770678  &  0.81234542 &  0.74884814 &  0.8180420  &  0.5393470 \\\\\n",
       "\t 1.1688741   & 2.0759008   & 1.7601405   & 1.6064459   & 1.9490456   &  1.3028421  &  0.45933154 &  0.5164121  &  0.8521795  &  0.9892272  & ...         &  0.41900645 &  0.7238875  &  1.3239469  &  2.1364876  &  1.74659650 &  1.4702205  &  1.89351230 &  1.25694930 &  0.8004066  &  0.7315398 \\\\\n",
       "\t 0.6479446   & 0.7512234   & 2.6337955   & 3.4525696   & 2.1161707   &  0.5200183  & -0.18861376 &  0.7799909  &  0.9328146  &  0.7006434  & ...         & -0.09793465 & -0.1368191  & -0.3400925  & -0.0895146  & -0.08037838 & -0.1925682  & -0.30459103 & -0.45431295 &  0.3141666  &  0.5815342 \\\\\n",
       "\t 0.4035074   & 1.2771034   & 2.5078283   & 1.2957095   & 1.4491787   &  0.4728490  & -1.39258560 & -0.6452687  &  0.4306412  &  0.1320061  & ...         &  0.37532545 &  0.2769523  &  0.2249676  &  0.1585749  &  0.40711823 &  0.5383992  & -0.02776744 &  0.20283211 &  0.3459054  &  0.3381487 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 | ... | V88 | V89 | V90 | V91 | V92 | V93 | V94 | V95 | V96 | V97 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.5020555   | 0.5421626   | 0.7223835   | 1.4288852   | 2.1365158   |  2.2811490  |  1.93627370 |  1.4688900  |  1.0088451  |  0.3802822  | ...         |  0.93104294 |  0.6102984  |  0.6388943  |  0.6846786  |  0.58323764 |  0.6405217  |  0.70858515 |  0.70501088 |  0.7138155  |  0.4337646  |\n",
       "| 0.1474864   | 0.8032087   | 0.3671757   | 0.2435429   | 0.0266927   | -0.2737281  |  0.09667076 | -0.7461207  | -1.6064626  | -1.1771292  | ...         | -0.53231711 | -0.3993053  |  0.1758674  |  1.1097011  |  2.43373800 |  2.7296122  |  1.73275310 |  0.03691512 | -1.2624415  | -0.2074816  |\n",
       "| 0.3166462   | 0.2431991   | 0.3704714   | 1.0637381   | 1.6781871   |  1.7595575  |  1.69771720 |  1.6121590  |  1.1681877  |  0.4999570  | ...         |  0.76422904 |  0.6106215  |  0.5529003  |  0.5667861  |  0.60400236 |  0.7770678  |  0.81234542 |  0.74884814 |  0.8180420  |  0.5393470  |\n",
       "| 1.1688741   | 2.0759008   | 1.7601405   | 1.6064459   | 1.9490456   |  1.3028421  |  0.45933154 |  0.5164121  |  0.8521795  |  0.9892272  | ...         |  0.41900645 |  0.7238875  |  1.3239469  |  2.1364876  |  1.74659650 |  1.4702205  |  1.89351230 |  1.25694930 |  0.8004066  |  0.7315398  |\n",
       "| 0.6479446   | 0.7512234   | 2.6337955   | 3.4525696   | 2.1161707   |  0.5200183  | -0.18861376 |  0.7799909  |  0.9328146  |  0.7006434  | ...         | -0.09793465 | -0.1368191  | -0.3400925  | -0.0895146  | -0.08037838 | -0.1925682  | -0.30459103 | -0.45431295 |  0.3141666  |  0.5815342  |\n",
       "| 0.4035074   | 1.2771034   | 2.5078283   | 1.2957095   | 1.4491787   |  0.4728490  | -1.39258560 | -0.6452687  |  0.4306412  |  0.1320061  | ...         |  0.37532545 |  0.2769523  |  0.2249676  |  0.1585749  |  0.40711823 |  0.5383992  | -0.02776744 |  0.20283211 |  0.3459054  |  0.3381487  |\n",
       "\n"
      ],
      "text/plain": [
       "     V2        V3        V4        V5        V6        V7         V8         \n",
       "[1,] 0.5020555 0.5421626 0.7223835 1.4288852 2.1365158  2.2811490  1.93627370\n",
       "[2,] 0.1474864 0.8032087 0.3671757 0.2435429 0.0266927 -0.2737281  0.09667076\n",
       "[3,] 0.3166462 0.2431991 0.3704714 1.0637381 1.6781871  1.7595575  1.69771720\n",
       "[4,] 1.1688741 2.0759008 1.7601405 1.6064459 1.9490456  1.3028421  0.45933154\n",
       "[5,] 0.6479446 0.7512234 2.6337955 3.4525696 2.1161707  0.5200183 -0.18861376\n",
       "[6,] 0.4035074 1.2771034 2.5078283 1.2957095 1.4491787  0.4728490 -1.39258560\n",
       "     V9         V10        V11        ... V88         V89        V90       \n",
       "[1,]  1.4688900  1.0088451  0.3802822 ...  0.93104294  0.6102984  0.6388943\n",
       "[2,] -0.7461207 -1.6064626 -1.1771292 ... -0.53231711 -0.3993053  0.1758674\n",
       "[3,]  1.6121590  1.1681877  0.4999570 ...  0.76422904  0.6106215  0.5529003\n",
       "[4,]  0.5164121  0.8521795  0.9892272 ...  0.41900645  0.7238875  1.3239469\n",
       "[5,]  0.7799909  0.9328146  0.7006434 ... -0.09793465 -0.1368191 -0.3400925\n",
       "[6,] -0.6452687  0.4306412  0.1320061 ...  0.37532545  0.2769523  0.2249676\n",
       "     V91        V92         V93        V94         V95         V96       \n",
       "[1,]  0.6846786  0.58323764  0.6405217  0.70858515  0.70501088  0.7138155\n",
       "[2,]  1.1097011  2.43373800  2.7296122  1.73275310  0.03691512 -1.2624415\n",
       "[3,]  0.5667861  0.60400236  0.7770678  0.81234542  0.74884814  0.8180420\n",
       "[4,]  2.1364876  1.74659650  1.4702205  1.89351230  1.25694930  0.8004066\n",
       "[5,] -0.0895146 -0.08037838 -0.1925682 -0.30459103 -0.45431295  0.3141666\n",
       "[6,]  0.1585749  0.40711823  0.5383992 -0.02776744  0.20283211  0.3459054\n",
       "     V97       \n",
       "[1,]  0.4337646\n",
       "[2,] -0.2074816\n",
       "[3,]  0.5393470\n",
       "[4,]  0.7315398\n",
       "[5,]  0.5815342\n",
       "[6,]  0.3381487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trclass <- sign(trainclass + 1); tsclass <- sign(testclass + 1) # Convert -1's to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plotting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's use line format\n",
    "plot(traindata[1,],type='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAABlBMVEUAAAD///+l2Z/dAAAA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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#multiple plots on single plot\n",
    "par(mfrow=c(2,2)) #2x2 grid\n",
    "plot(traindata[1,],type='l')\n",
    "plot(traindata[2,],type='l')\n",
    "plot(traindata[3,],type='l')\n",
    "plot(traindata[4,],type='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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\ngEgAAvwPyyjWKAunUn4AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#problem with limits?\n",
    "lim=max(abs(traindata[1:4,])) #maximum of the absolute value of the observations for first 4 time series\n",
    "plot(traindata[1,],type='l',col=trainclass[1]+3,ylim=c(-1.1*lim,1.1*lim))\n",
    "points(traindata[2,],type='l',col=trainclass[2]+3)\n",
    "points(traindata[3,],type='l',col=trainclass[3]+3)\n",
    "points(traindata[4,],type='l',col=trainclass[4]+3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task a: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'penalized' was built under R version 3.6.3\"Welcome to penalized. For extended examples, see vignette(\"penalized\").\n"
     ]
    }
   ],
   "source": [
    "require(penalized, quietly = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L1 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 8.374801 \tcvl= -46.70331 \n",
      "lambda= 13.55071 \tcvl= -55.44112 \n",
      "lambda= 5.175911 \tcvl= -39.97299 \n",
      "lambda= 3.198889 \tcvl= -36.3063 \n",
      "lambda= 1.977022 \tcvl= -36.3903 \n",
      "lambda= 2.645125 \tcvl= -35.89841 \n",
      "lambda= 2.616473 \tcvl= -35.90233 \n",
      "lambda= 2.676443 \tcvl= -35.89494 \n",
      "lambda= 2.875999 \tcvl= -35.91903 \n",
      "lambda= 2.787286 \tcvl= -35.89266 \n",
      "lambda= 2.748065 \tcvl= -35.88762 \n",
      "lambda= 2.736801 \tcvl= -35.88916 \n",
      "lambda= 2.755413 \tcvl= -35.88672 \n",
      "lambda= 2.767587 \tcvl= -35.88632 \n",
      "lambda= 2.765108 \tcvl= -35.88565 \n",
      "lambda= 2.76203 \tcvl= -35.88598 \n",
      "lambda= 2.764352 \tcvl= -35.88573 \n",
      "lambda= 2.766055 \tcvl= -35.88585 \n",
      "lambda= 2.765204 \tcvl= -35.88564 \n",
      "lambda= 2.765529 \tcvl= -35.88569 \n"
     ]
    }
   ],
   "source": [
    "fit2a <- optL1(response = as.factor(trclass), penalized=traindata ,fusedl = TRUE, fold = 10, model = \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.76520351963132"
      ],
      "text/latex": [
       "2.76520351963132"
      ],
      "text/markdown": [
       "2.76520351963132"
      ],
      "text/plain": [
       "[1] 2.765204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-35.8856422534832"
      ],
      "text/latex": [
       "-35.8856422534832"
      ],
      "text/markdown": [
       "-35.8856422534832"
      ],
      "text/plain": [
       "[1] -35.88564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2a$lambda; fit2a$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L2 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= Inf \tcvl= -63.62315 \n",
      "lambda= 1 \tcvl= -36.95078 \n",
      "lambda= 10 \tcvl= -43.42675 \n",
      "lambda= 0.1 \tcvl= -36.70208 \n",
      "lambda= 0.01 \tcvl= -37.33339 \n",
      "lambda= 0.3881464 \tcvl= -37.64095 \n",
      "lambda= 0.6218536 \tcvl= -38.1167 \n",
      "lambda= 0.2437073 \tcvl= -36.7799 \n",
      "lambda= 0.1544391 \tcvl= -36.63092 \n",
      "lambda= 0.1536404 \tcvl= -36.62696 \n",
      "lambda= 0.09877463 \tcvl= -36.82554 \n",
      "lambda= 0.1326835 \tcvl= -36.66819 \n",
      "lambda= 0.1462545 \tcvl= -36.63122 \n",
      "lambda= 0.1503742 \tcvl= -36.62309 \n",
      "lambda= 0.1513672 \tcvl= -36.62426 \n",
      "lambda= 0.1488006 \tcvl= -36.62329 \n",
      "lambda= 0.1497139 \tcvl= -36.62231 \n",
      "lambda= 0.1496325 \tcvl= -36.62221 \n",
      "lambda= 0.1493148 \tcvl= -36.62184 \n",
      "lambda= 0.1491184 \tcvl= -36.62231 \n",
      "lambda= 0.1493886 \tcvl= -36.62193 \n",
      "lambda= 0.1492398 \tcvl= -36.62193 \n",
      "lambda= 0.1493152 \tcvl= -36.62184 \n",
      "lambda= 0.1492861 \tcvl= -36.62181 \n",
      "lambda= 0.1492684 \tcvl= -36.62184 \n"
     ]
    }
   ],
   "source": [
    "fit2a1 <- optL2(response = as.factor(trclass), penalized=traindata ,fusedl = TRUE, fold = 10,\n",
    "               model = \"logistic\", lambda1 = fit2a$lambda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.149286113639008"
      ],
      "text/latex": [
       "0.149286113639008"
      ],
      "text/markdown": [
       "0.149286113639008"
      ],
      "text/plain": [
       "[1] 0.1492861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-36.6218071621438"
      ],
      "text/latex": [
       "-36.6218071621438"
      ],
      "text/markdown": [
       "-36.6218071621438"
      ],
      "text/plain": [
       "[1] -36.62181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2a1$lambda; fit2a1$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cross Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 8.273808 \tcvl= -46.55654 \n",
      "lambda= 13.3873 \tcvl= -55.41976 \n",
      "lambda= 5.113494 \tcvl= -39.718 \n",
      "lambda= 3.160313 \tcvl= -36.68453 \n",
      "lambda= 1.953181 \tcvl= -35.95552 \n",
      "lambda= 1.55135 \tcvl= -35.99962 \n",
      "lambda= 1.875977 \tcvl= -36.01572 \n",
      "lambda= 2.414265 \tcvl= -35.81494 \n",
      "lambda= 2.69923 \tcvl= -36.06982 \n",
      "lambda= 2.238146 \tcvl= -35.81539 \n",
      "lambda= 2.327415 \tcvl= -35.81164 \n",
      "lambda= 2.329033 \tcvl= -35.81171 \n",
      "lambda= 2.293317 \tcvl= -35.81089 \n",
      "lambda= 2.291445 \tcvl= -35.81089 \n",
      "lambda= 2.291642 \tcvl= -35.81089 \n",
      "lambda= 2.264894 \tcvl= -35.81132 \n",
      "lambda= 2.281304 \tcvl= -35.81096 \n",
      "lambda= 2.286473 \tcvl= -35.81091 \n",
      "lambda= 2.289058 \tcvl= -35.8109 \n",
      "lambda= 2.29035 \tcvl= -35.81089 \n",
      "lambda= 2.290996 \tcvl= -35.81089 \n"
     ]
    }
   ],
   "source": [
    "fit2a2 <- optL1(response = as.factor(trclass), penalized=traindata ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda2 = fit2a1$lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.29144540224507"
      ],
      "text/latex": [
       "2.29144540224507"
      ],
      "text/markdown": [
       "2.29144540224507"
      ],
      "text/plain": [
       "[1] 2.291445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-35.8108927287704"
      ],
      "text/latex": [
       "-35.8108927287704"
      ],
      "text/markdown": [
       "-35.8108927287704"
      ],
      "text/plain": [
       "[1] -35.81089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2a2$lambda; fit2a2$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cvl is increased!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Re-tuning L2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= Inf \tcvl= -63.41946 \n",
      "lambda= 1 \tcvl= -36.09964 \n",
      "lambda= 10 \tcvl= -42.38113 \n",
      "lambda= 0.1 \tcvl= -34.86183 \n",
      "lambda= 0.01 \tcvl= -35.96723 \n",
      "lambda= 0.3881464 \tcvl= -35.50943 \n",
      "lambda= 0.6218536 \tcvl= -35.91821 \n",
      "lambda= 0.2437073 \tcvl= -34.83896 \n",
      "lambda= 0.1544391 \tcvl= -34.6626 \n",
      "lambda= 0.1124857 \tcvl= -34.79015 \n",
      "lambda= 0.1732303 \tcvl= -34.64507 \n",
      "lambda= 0.1772798 \tcvl= -34.63887 \n",
      "lambda= 0.2026529 \tcvl= -34.64891 \n",
      "lambda= 0.1869444 \tcvl= -34.64268 \n",
      "lambda= 0.1807098 \tcvl= -34.64056 \n",
      "lambda= 0.175733 \tcvl= -34.64036 \n",
      "lambda= 0.178152 \tcvl= -34.63927 \n",
      "lambda= 0.1773263 \tcvl= -34.63888 \n",
      "lambda= 0.176689 \tcvl= -34.6387 \n",
      "lambda= 0.1763239 \tcvl= -34.63926 \n",
      "lambda= 0.1769147 \tcvl= -34.63877 \n",
      "lambda= 0.1765495 \tcvl= -34.63887 \n",
      "lambda= 0.1767656 \tcvl= -34.63872 \n",
      "lambda= 0.1766357 \tcvl= -34.63872 \n",
      "lambda= 0.1766981 \tcvl= -34.6387 \n",
      "lambda= 0.1766669 \tcvl= -34.63869 \n"
     ]
    }
   ],
   "source": [
    "fit2a3 <- optL2(response = as.factor(trclass), penalized=traindata ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda1 = fit2a2$lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.176666905984604"
      ],
      "text/latex": [
       "0.176666905984604"
      ],
      "text/markdown": [
       "0.176666905984604"
      ],
      "text/plain": [
       "[1] 0.1766669"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-34.638694170729"
      ],
      "text/latex": [
       "-34.638694170729"
      ],
      "text/markdown": [
       "-34.638694170729"
      ],
      "text/plain": [
       "[1] -34.63869"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2a3$lambda; fit2a3$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cvl is increased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-tuning L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 8.343195 \tcvl= -47.04823 \n",
      "lambda= 13.49957 \tcvl= -55.48221 \n",
      "lambda= 5.156378 \tcvl= -40.65456 \n",
      "lambda= 3.186817 \tcvl= -38.02194 \n",
      "lambda= 1.969561 \tcvl= -37.55926 \n",
      "lambda= 1.945013 \tcvl= -37.54634 \n",
      "lambda= 1.202084 \tcvl= -37.15555 \n",
      "lambda= 0.742929 \tcvl= -38.00784 \n",
      "lambda= 1.485858 \tcvl= -37.29289 \n",
      "lambda= 1.026703 \tcvl= -37.32141 \n",
      "lambda= 1.266253 \tcvl= -37.17358 \n",
      "lambda= 1.135095 \tcvl= -37.14707 \n",
      "lambda= 1.114778 \tcvl= -37.16812 \n",
      "lambda= 1.163837 \tcvl= -37.1346 \n",
      "lambda= 1.164271 \tcvl= -37.13551 \n",
      "lambda= 1.151965 \tcvl= -37.13423 \n",
      "lambda= 1.145521 \tcvl= -37.1383 \n",
      "lambda= 1.157807 \tcvl= -37.13469 \n",
      "lambda= 1.149503 \tcvl= -37.13515 \n",
      "lambda= 1.154196 \tcvl= -37.13434 \n",
      "lambda= 1.151024 \tcvl= -37.13455 \n",
      "lambda= 1.152873 \tcvl= -37.13424 \n",
      "lambda= 1.152182 \tcvl= -37.13419 \n",
      "lambda= 1.152393 \tcvl= -37.1342 \n"
     ]
    }
   ],
   "source": [
    "fit2a4 <- optL1(response = as.factor(trclass), penalized=traindata ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda2 = fit2a3$lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.15218216053559"
      ],
      "text/latex": [
       "1.15218216053559"
      ],
      "text/markdown": [
       "1.15218216053559"
      ],
      "text/plain": [
       "[1] 1.152182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-37.1341903892906"
      ],
      "text/latex": [
       "-37.1341903892906"
      ],
      "text/markdown": [
       "-37.1341903892906"
      ],
      "text/plain": [
       "[1] -37.13419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2a4$lambda; fit2a4$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cvl is decreased!. Best pair is **L1 = 2.2914** and **L2 = 0.1767**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.291445 0.1766669"
     ]
    }
   ],
   "source": [
    "l1 = fit2a2$lambda; l2 = fit2a3$lambda; cat(l1,l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2a <-penalized(response = as.factor(trclass), penalized = traindata, fusedl = TRUE,\n",
    "                 model = \"logistic\", lambda1 = l1, lambda2 = l2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Penalized logistic regression object\n",
       "97 regression coefficients of which 15 are non-zero\n",
       "\n",
       "Loglikelihood =\t -27.10339 \n",
       "L1 penalty =\t 10.47812 \tat lambda1 =  2.291445 \n",
       "L2 penalty =\t 0.7876814 \tat lambda2 =  0.1766669 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2a <- predict(model2a, penalized = testdata  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2aClass <- 1*(preds2a >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2aClass\n",
       "tsclass  0  1\n",
       "      0 24 12\n",
       "      1  6 58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  82 %"
     ]
    }
   ],
   "source": [
    "cat(\"CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2aClass)  ) )\n",
    "acc = sum(preds2aClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task b: Interpretting Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coefficients = c(model2a@unpenalized,model2a@penalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.232199169434218</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>-0.0472562659770895</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>7</dt>\n",
       "\t\t<dd>-0.0841960758319244</dd>\n",
       "\t<dt>8</dt>\n",
       "\t\t<dd>-0.391147256887169</dd>\n",
       "\t<dt>9</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>10</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>11</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>12</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>13</dt>\n",
       "\t\t<dd>0.790640014188663</dd>\n",
       "\t<dt>14</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>16</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>17</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>18</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>19</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>20</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>21</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>22</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>23</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>25</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>26</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>27</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>28</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>29</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>30</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>31</dt>\n",
       "\t\t<dd>-0.224136477063067</dd>\n",
       "\t<dt>32</dt>\n",
       "\t\t<dd>-0.224136477063067</dd>\n",
       "\t<dt>33</dt>\n",
       "\t\t<dd>-0.224136477063067</dd>\n",
       "\t<dt>34</dt>\n",
       "\t\t<dd>-0.104883911047582</dd>\n",
       "\t<dt>35</dt>\n",
       "\t\t<dd>-0.104883911047582</dd>\n",
       "\t<dt>36</dt>\n",
       "\t\t<dd>-0.104883911047582</dd>\n",
       "\t<dt>37</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>38</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>39</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>40</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>41</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>42</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>43</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>44</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>45</dt>\n",
       "\t\t<dd>0.463257841520017</dd>\n",
       "\t<dt>46</dt>\n",
       "\t\t<dd>0.463257841520017</dd>\n",
       "\t<dt>47</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>48</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>49</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>50</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>51</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>52</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>53</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>54</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>55</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>56</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>57</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>58</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>59</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>60</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>61</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>62</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>63</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>64</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>65</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>66</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>67</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>68</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>69</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>70</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>71</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>72</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>73</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>74</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>75</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>76</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>77</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>78</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>79</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>80</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>81</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>82</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>83</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>84</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>85</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>86</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>87</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>88</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>89</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>90</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>91</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>92</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>93</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>94</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>95</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>96</dt>\n",
       "\t\t<dd>-0.672948172012308</dd>\n",
       "\t<dt>97</dt>\n",
       "\t\t<dd>-0.672948172012308</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.232199169434218\n",
       "\\item[2] -0.0472562659770895\n",
       "\\item[3] 0\n",
       "\\item[4] 0\n",
       "\\item[5] 0\n",
       "\\item[6] 0\n",
       "\\item[7] -0.0841960758319244\n",
       "\\item[8] -0.391147256887169\n",
       "\\item[9] 0\n",
       "\\item[10] 0\n",
       "\\item[11] 0\n",
       "\\item[12] 0\n",
       "\\item[13] 0.790640014188663\n",
       "\\item[14] 0\n",
       "\\item[15] 0\n",
       "\\item[16] 0\n",
       "\\item[17] 0\n",
       "\\item[18] 0\n",
       "\\item[19] 0\n",
       "\\item[20] 0\n",
       "\\item[21] 0\n",
       "\\item[22] 0\n",
       "\\item[23] 0\n",
       "\\item[24] 0\n",
       "\\item[25] 0\n",
       "\\item[26] 0\n",
       "\\item[27] 0\n",
       "\\item[28] 0\n",
       "\\item[29] 0\n",
       "\\item[30] 0\n",
       "\\item[31] -0.224136477063067\n",
       "\\item[32] -0.224136477063067\n",
       "\\item[33] -0.224136477063067\n",
       "\\item[34] -0.104883911047582\n",
       "\\item[35] -0.104883911047582\n",
       "\\item[36] -0.104883911047582\n",
       "\\item[37] 0\n",
       "\\item[38] 0\n",
       "\\item[39] 0\n",
       "\\item[40] 0\n",
       "\\item[41] 0\n",
       "\\item[42] 0\n",
       "\\item[43] 0\n",
       "\\item[44] 0\n",
       "\\item[45] 0.463257841520017\n",
       "\\item[46] 0.463257841520017\n",
       "\\item[47] 0\n",
       "\\item[48] 0\n",
       "\\item[49] 0\n",
       "\\item[50] 0\n",
       "\\item[51] 0\n",
       "\\item[52] 0\n",
       "\\item[53] 0\n",
       "\\item[54] 0\n",
       "\\item[55] 0\n",
       "\\item[56] 0\n",
       "\\item[57] 0\n",
       "\\item[58] 0\n",
       "\\item[59] 0\n",
       "\\item[60] 0\n",
       "\\item[61] 0\n",
       "\\item[62] 0\n",
       "\\item[63] 0\n",
       "\\item[64] 0\n",
       "\\item[65] 0\n",
       "\\item[66] 0\n",
       "\\item[67] 0\n",
       "\\item[68] 0\n",
       "\\item[69] 0\n",
       "\\item[70] 0\n",
       "\\item[71] 0\n",
       "\\item[72] 0\n",
       "\\item[73] 0\n",
       "\\item[74] 0\n",
       "\\item[75] 0\n",
       "\\item[76] 0\n",
       "\\item[77] 0\n",
       "\\item[78] 0\n",
       "\\item[79] 0\n",
       "\\item[80] 0\n",
       "\\item[81] 0\n",
       "\\item[82] 0\n",
       "\\item[83] 0\n",
       "\\item[84] 0\n",
       "\\item[85] 0\n",
       "\\item[86] 0\n",
       "\\item[87] 0\n",
       "\\item[88] 0\n",
       "\\item[89] 0\n",
       "\\item[90] 0\n",
       "\\item[91] 0\n",
       "\\item[92] 0\n",
       "\\item[93] 0\n",
       "\\item[94] 0\n",
       "\\item[95] 0\n",
       "\\item[96] -0.672948172012308\n",
       "\\item[97] -0.672948172012308\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.2321991694342182\n",
       ":   -0.04725626597708953\n",
       ":   04\n",
       ":   05\n",
       ":   06\n",
       ":   07\n",
       ":   -0.08419607583192448\n",
       ":   -0.3911472568871699\n",
       ":   010\n",
       ":   011\n",
       ":   012\n",
       ":   013\n",
       ":   0.79064001418866314\n",
       ":   015\n",
       ":   016\n",
       ":   017\n",
       ":   018\n",
       ":   019\n",
       ":   020\n",
       ":   021\n",
       ":   022\n",
       ":   023\n",
       ":   024\n",
       ":   025\n",
       ":   026\n",
       ":   027\n",
       ":   028\n",
       ":   029\n",
       ":   030\n",
       ":   031\n",
       ":   -0.22413647706306732\n",
       ":   -0.22413647706306733\n",
       ":   -0.22413647706306734\n",
       ":   -0.10488391104758235\n",
       ":   -0.10488391104758236\n",
       ":   -0.10488391104758237\n",
       ":   038\n",
       ":   039\n",
       ":   040\n",
       ":   041\n",
       ":   042\n",
       ":   043\n",
       ":   044\n",
       ":   045\n",
       ":   0.46325784152001746\n",
       ":   0.46325784152001747\n",
       ":   048\n",
       ":   049\n",
       ":   050\n",
       ":   051\n",
       ":   052\n",
       ":   053\n",
       ":   054\n",
       ":   055\n",
       ":   056\n",
       ":   057\n",
       ":   058\n",
       ":   059\n",
       ":   060\n",
       ":   061\n",
       ":   062\n",
       ":   063\n",
       ":   064\n",
       ":   065\n",
       ":   066\n",
       ":   067\n",
       ":   068\n",
       ":   069\n",
       ":   070\n",
       ":   071\n",
       ":   072\n",
       ":   073\n",
       ":   074\n",
       ":   075\n",
       ":   076\n",
       ":   077\n",
       ":   078\n",
       ":   079\n",
       ":   080\n",
       ":   081\n",
       ":   082\n",
       ":   083\n",
       ":   084\n",
       ":   085\n",
       ":   086\n",
       ":   087\n",
       ":   088\n",
       ":   089\n",
       ":   090\n",
       ":   091\n",
       ":   092\n",
       ":   093\n",
       ":   094\n",
       ":   095\n",
       ":   096\n",
       ":   -0.67294817201230897\n",
       ":   -0.672948172012308\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)                                                             \n",
       " 0.23219917 -0.04725627  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       "-0.08419608 -0.39114726  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.79064001  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       "-0.22413648 -0.22413648 -0.22413648 -0.10488391 -0.10488391 -0.10488391 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.46325784  0.46325784  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 -0.67294817 \n",
       "            \n",
       "-0.67294817 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>100</li>\n",
       "\t<li>96</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 100\n",
       "\\item 96\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 100\n",
       "2. 96\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 100  96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only **15** coefficients of the model is not equal to zero out of **96**. When we look at the coefficients, an interesting fact draws attention. We can see that many consecutive coefficients are equal. This outcome can be attributed to the fused loss function as equal consecutive coefficients would contribute zero to the fused loss function. Consecutive non-zero coefficients are as below:\n",
    "\n",
    "$\\theta_0 \\neq \\theta_1$   \n",
    "$\\theta_6 \\neq \\theta_7$   \n",
    "$\\theta_{30} = \\theta_{31} = \\theta_{32}$   \n",
    "$\\theta_{33} = \\theta_{34} = \\theta_{35}$    \n",
    "$\\theta_{44} = \\theta_{45}$   \n",
    "$\\theta_{95} = \\theta_{96}$   \n",
    "\n",
    "Among coefficients, the one with highest values is $\\theta_{12}$ and the ones with lowest value are $\\theta_{95} = \\theta_{96}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task c: Using Differences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diffstrain = traindata[,-1] - traindata[,- dim(traindata)[2] ]\n",
    "diffstest = testdata[,-1] - testdata[,- dim(testdata)[2] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 5.59949 \tcvl= -51.99793 \n",
      "lambda= 9.060165 \tcvl= -56.39873 \n",
      "lambda= 3.460675 \tcvl= -49.14314 \n",
      "lambda= 2.138815 \tcvl= -43.9736 \n",
      "lambda= 1.32186 \tcvl= -40.42611 \n",
      "lambda= 0.8169546 \tcvl= -40.92711 \n",
      "lambda= 1.192344 \tcvl= -39.96897 \n",
      "lambda= 1.110594 \tcvl= -39.8498 \n",
      "lambda= 1.077145 \tcvl= -39.86034 \n",
      "lambda= 1.104112 \tcvl= -39.84348 \n",
      "lambda= 1.097165 \tcvl= -39.84234 \n",
      "lambda= 1.09929 \tcvl= -39.8419 \n",
      "lambda= 1.099579 \tcvl= -39.84185 \n",
      "lambda= 1.10131 \tcvl= -39.84156 \n",
      "lambda= 1.102381 \tcvl= -39.8419 \n",
      "lambda= 1.100927 \tcvl= -39.84162 \n",
      "lambda= 1.101719 \tcvl= -39.8415 \n",
      "lambda= 1.101972 \tcvl= -39.84154 \n",
      "lambda= 1.101682 \tcvl= -39.8415 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2b1 <- optL1(response = as.factor(trclass), penalized=diffstrain ,fusedl = TRUE, fold = 10, model = \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.10171927617207"
      ],
      "text/latex": [
       "1.10171927617207"
      ],
      "text/markdown": [
       "1.10171927617207"
      ],
      "text/plain": [
       "[1] 1.101719"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-39.841498890703"
      ],
      "text/latex": [
       "-39.841498890703"
      ],
      "text/markdown": [
       "-39.841498890703"
      ],
      "text/plain": [
       "[1] -39.8415"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2b1$lambda; fit2b1$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= Inf \tcvl= -63.15148 \n",
      "lambda= 1 \tcvl= -40.87305 \n",
      "lambda= 10 \tcvl= -55.08197 \n",
      "lambda= 0.1 \tcvl= -39.48898 \n",
      "lambda= 0.01 \tcvl= -39.84736 \n",
      "lambda= 0.3881464 \tcvl= -40.1331 \n",
      "lambda= 0.6218536 \tcvl= -40.42495 \n",
      "lambda= 0.2437073 \tcvl= -39.35899 \n",
      "lambda= 0.1544391 \tcvl= -39.40302 \n",
      "lambda= 0.2089226 \tcvl= -39.36683 \n",
      "lambda= 0.2492229 \tcvl= -39.38044 \n",
      "lambda= 0.2274182 \tcvl= -39.36134 \n",
      "lambda= 0.2374854 \tcvl= -39.36182 \n",
      "lambda= 0.2413308 \tcvl= -39.36468 \n",
      "lambda= 0.2458141 \tcvl= -39.37307 \n",
      "lambda= 0.2427995 \tcvl= -39.36685 \n",
      "lambda= 0.244512 \tcvl= -39.37035 \n",
      "lambda= 0.2433606 \tcvl= -39.36798 \n",
      "lambda= 0.2440147 \tcvl= -39.36932 \n",
      "lambda= 0.2435749 \tcvl= -39.36842 \n",
      "lambda= 0.2438247 \tcvl= -39.36893 \n",
      "lambda= 0.2436567 \tcvl= -39.36859 \n",
      "lambda= 0.2437521 \tcvl= -39.36878 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2b2 <- optL2(response = as.factor(trclass), penalized=diffstrain ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda1 = fit2b1$lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.243707297724792"
      ],
      "text/latex": [
       "0.243707297724792"
      ],
      "text/markdown": [
       "0.243707297724792"
      ],
      "text/plain": [
       "[1] 0.2437073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-39.358987140136"
      ],
      "text/latex": [
       "-39.358987140136"
      ],
      "text/markdown": [
       "-39.358987140136"
      ],
      "text/plain": [
       "[1] -39.35899"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2b2$lambda; fit2b2$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(Note: I could note tune further because of crashes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.101719 0.2437073"
     ]
    }
   ],
   "source": [
    "l1 = fit2b1$lambda; l2 = fit2b2$lambda; cat(l1,l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "model2b <-penalized(response = as.factor(trclass), penalized = diffstrain, fusedl = TRUE,\n",
    "                 model = \"logistic\", lambda1 = l1, lambda2 = l2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Penalized logistic regression object\n",
       "96 regression coefficients of which 21 are non-zero\n",
       "\n",
       "Loglikelihood =\t -29.43123 \n",
       "L1 penalty =\t 11.05014 \tat lambda1 =  1.101719 \n",
       "L2 penalty =\t 2.022953 \tat lambda2 =  0.2437073 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2b <- predict(model2b, penalized = diffstest  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2bClass <- 1*(preds2b >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL A CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2aClass\n",
       "tsclass  0  1\n",
       "      0 24 12\n",
       "      1  6 58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  82 %\n",
      "\n",
      "MODEL B CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2bClass\n",
       "tsclass  0  1\n",
       "      0 27  9\n",
       "      1  7 57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  84 %"
     ]
    }
   ],
   "source": [
    "cat(\"MODEL A CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2aClass)  ) )\n",
    "acc = sum(preds2aClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\\n\\n\" )\n",
    "\n",
    "cat(\"MODEL B CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2bClass)  ) )\n",
    "acc = sum(preds2bClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at confusion matricies, in the second model, **3 more observations** from **class -1**, and **1 less observation** from **class 1** were predicted correctly. Overall, second model is better looking at accuracy scores which are **82%** and **84%** in order.         \n",
    "To sum up, **Model B** has better **Accuracy** and **Specifity** rate and **Model A** has better **Sensitivity** rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Task d: Interpretting Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CoefficientsB = c(model2b@unpenalized,model2b@penalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-0.58923663779798</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>0.303994674218526</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0.893885949063488</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>-0.453347090558684</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>-0.0521083323782678</dd>\n",
       "\t<dt>7</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>8</dt>\n",
       "\t\t<dd>0.278239390994089</dd>\n",
       "\t<dt>9</dt>\n",
       "\t\t<dd>0.287141597524279</dd>\n",
       "\t<dt>10</dt>\n",
       "\t\t<dd>0.287141597524279</dd>\n",
       "\t<dt>11</dt>\n",
       "\t\t<dd>0.281684139093484</dd>\n",
       "\t<dt>12</dt>\n",
       "\t\t<dd>0.281684139093484</dd>\n",
       "\t<dt>13</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>14</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>16</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>17</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>18</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>19</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>20</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>21</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>22</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>23</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>25</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>26</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>27</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>28</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>29</dt>\n",
       "\t\t<dd>-0.236931277343182</dd>\n",
       "\t<dt>30</dt>\n",
       "\t\t<dd>-0.236931277343182</dd>\n",
       "\t<dt>31</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>32</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>33</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>34</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>35</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>36</dt>\n",
       "\t\t<dd>0.556061989193453</dd>\n",
       "\t<dt>37</dt>\n",
       "\t\t<dd>0.602121232319494</dd>\n",
       "\t<dt>38</dt>\n",
       "\t\t<dd>0.997918362341551</dd>\n",
       "\t<dt>39</dt>\n",
       "\t\t<dd>0.997918362341551</dd>\n",
       "\t<dt>40</dt>\n",
       "\t\t<dd>0.997918362341551</dd>\n",
       "\t<dt>41</dt>\n",
       "\t\t<dd>0.244315568107497</dd>\n",
       "\t<dt>42</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>43</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>44</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>45</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>46</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>47</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>48</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>49</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>50</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>51</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>52</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>53</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>54</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>55</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>56</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>57</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>58</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>59</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>60</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>61</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>62</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>63</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>64</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>65</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>66</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>67</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>68</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>69</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>70</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>71</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>72</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>73</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>74</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>75</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>76</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>77</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>78</dt>\n",
       "\t\t<dd>-0.825733741530411</dd>\n",
       "\t<dt>79</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>80</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>81</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>82</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>83</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>84</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>85</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>86</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>87</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>88</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>89</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>90</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>91</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>92</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>93</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>94</dt>\n",
       "\t\t<dd>-0.607413693627478</dd>\n",
       "\t<dt>95</dt>\n",
       "\t\t<dd>-0.607413693627478</dd>\n",
       "\t<dt>96</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -0.58923663779798\n",
       "\\item[2] 0.303994674218526\n",
       "\\item[3] 0.893885949063488\n",
       "\\item[4] 0\n",
       "\\item[5] -0.453347090558684\n",
       "\\item[6] -0.0521083323782678\n",
       "\\item[7] 0\n",
       "\\item[8] 0.278239390994089\n",
       "\\item[9] 0.287141597524279\n",
       "\\item[10] 0.287141597524279\n",
       "\\item[11] 0.281684139093484\n",
       "\\item[12] 0.281684139093484\n",
       "\\item[13] 0\n",
       "\\item[14] 0\n",
       "\\item[15] 0\n",
       "\\item[16] 0\n",
       "\\item[17] 0\n",
       "\\item[18] 0\n",
       "\\item[19] 0\n",
       "\\item[20] 0\n",
       "\\item[21] 0\n",
       "\\item[22] 0\n",
       "\\item[23] 0\n",
       "\\item[24] 0\n",
       "\\item[25] 0\n",
       "\\item[26] 0\n",
       "\\item[27] 0\n",
       "\\item[28] 0\n",
       "\\item[29] -0.236931277343182\n",
       "\\item[30] -0.236931277343182\n",
       "\\item[31] 0\n",
       "\\item[32] 0\n",
       "\\item[33] 0\n",
       "\\item[34] 0\n",
       "\\item[35] 0\n",
       "\\item[36] 0.556061989193453\n",
       "\\item[37] 0.602121232319494\n",
       "\\item[38] 0.997918362341551\n",
       "\\item[39] 0.997918362341551\n",
       "\\item[40] 0.997918362341551\n",
       "\\item[41] 0.244315568107497\n",
       "\\item[42] 0\n",
       "\\item[43] 0\n",
       "\\item[44] 0\n",
       "\\item[45] 0\n",
       "\\item[46] 0\n",
       "\\item[47] 0\n",
       "\\item[48] 0\n",
       "\\item[49] 0\n",
       "\\item[50] 0\n",
       "\\item[51] 0\n",
       "\\item[52] 0\n",
       "\\item[53] 0\n",
       "\\item[54] 0\n",
       "\\item[55] 0\n",
       "\\item[56] 0\n",
       "\\item[57] 0\n",
       "\\item[58] 0\n",
       "\\item[59] 0\n",
       "\\item[60] 0\n",
       "\\item[61] 0\n",
       "\\item[62] 0\n",
       "\\item[63] 0\n",
       "\\item[64] 0\n",
       "\\item[65] 0\n",
       "\\item[66] 0\n",
       "\\item[67] 0\n",
       "\\item[68] 0\n",
       "\\item[69] 0\n",
       "\\item[70] 0\n",
       "\\item[71] 0\n",
       "\\item[72] 0\n",
       "\\item[73] 0\n",
       "\\item[74] 0\n",
       "\\item[75] 0\n",
       "\\item[76] 0\n",
       "\\item[77] 0\n",
       "\\item[78] -0.825733741530411\n",
       "\\item[79] 0\n",
       "\\item[80] 0\n",
       "\\item[81] 0\n",
       "\\item[82] 0\n",
       "\\item[83] 0\n",
       "\\item[84] 0\n",
       "\\item[85] 0\n",
       "\\item[86] 0\n",
       "\\item[87] 0\n",
       "\\item[88] 0\n",
       "\\item[89] 0\n",
       "\\item[90] 0\n",
       "\\item[91] 0\n",
       "\\item[92] 0\n",
       "\\item[93] 0\n",
       "\\item[94] -0.607413693627478\n",
       "\\item[95] -0.607413693627478\n",
       "\\item[96] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -0.589236637797982\n",
       ":   0.3039946742185263\n",
       ":   0.8938859490634884\n",
       ":   05\n",
       ":   -0.4533470905586846\n",
       ":   -0.05210833237826787\n",
       ":   08\n",
       ":   0.2782393909940899\n",
       ":   0.28714159752427910\n",
       ":   0.28714159752427911\n",
       ":   0.28168413909348412\n",
       ":   0.28168413909348413\n",
       ":   014\n",
       ":   015\n",
       ":   016\n",
       ":   017\n",
       ":   018\n",
       ":   019\n",
       ":   020\n",
       ":   021\n",
       ":   022\n",
       ":   023\n",
       ":   024\n",
       ":   025\n",
       ":   026\n",
       ":   027\n",
       ":   028\n",
       ":   029\n",
       ":   -0.23693127734318230\n",
       ":   -0.23693127734318231\n",
       ":   032\n",
       ":   033\n",
       ":   034\n",
       ":   035\n",
       ":   036\n",
       ":   0.55606198919345337\n",
       ":   0.60212123231949438\n",
       ":   0.99791836234155139\n",
       ":   0.99791836234155140\n",
       ":   0.99791836234155141\n",
       ":   0.24431556810749742\n",
       ":   043\n",
       ":   044\n",
       ":   045\n",
       ":   046\n",
       ":   047\n",
       ":   048\n",
       ":   049\n",
       ":   050\n",
       ":   051\n",
       ":   052\n",
       ":   053\n",
       ":   054\n",
       ":   055\n",
       ":   056\n",
       ":   057\n",
       ":   058\n",
       ":   059\n",
       ":   060\n",
       ":   061\n",
       ":   062\n",
       ":   063\n",
       ":   064\n",
       ":   065\n",
       ":   066\n",
       ":   067\n",
       ":   068\n",
       ":   069\n",
       ":   070\n",
       ":   071\n",
       ":   072\n",
       ":   073\n",
       ":   074\n",
       ":   075\n",
       ":   076\n",
       ":   077\n",
       ":   078\n",
       ":   -0.82573374153041179\n",
       ":   080\n",
       ":   081\n",
       ":   082\n",
       ":   083\n",
       ":   084\n",
       ":   085\n",
       ":   086\n",
       ":   087\n",
       ":   088\n",
       ":   089\n",
       ":   090\n",
       ":   091\n",
       ":   092\n",
       ":   093\n",
       ":   094\n",
       ":   -0.60741369362747895\n",
       ":   -0.60741369362747896\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)                                                             \n",
       "-0.58923664  0.30399467  0.89388595  0.00000000 -0.45334709 -0.05210833 \n",
       "                                                                        \n",
       " 0.00000000  0.27823939  0.28714160  0.28714160  0.28168414  0.28168414 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000 -0.23693128 -0.23693128 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.55606199 \n",
       "                                                                        \n",
       " 0.60212123  0.99791836  0.99791836  0.99791836  0.24431557  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 -0.82573374 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "                                                                        \n",
       " 0.00000000  0.00000000  0.00000000 -0.60741369 -0.60741369  0.00000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CoefficientsB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "21"
      ],
      "text/latex": [
       "21"
      ],
      "text/markdown": [
       "21"
      ],
      "text/plain": [
       "[1] 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(coef(model2b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>100</li>\n",
       "\t<li>95</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 100\n",
       "\\item 95\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 100\n",
       "2. 95\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 100  95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(diffstest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**21** coefficients of the model is not equal to zero out of **95**. This model has more non-zero coefficients compared to **Model A**. Again, many consecutive coefficients are equal in this model too as expected but there are more exceptions in this one. Non-zero coefficients can be seen below:\n",
    "\n",
    "$\\theta_0 \\neq \\theta_1 \\neq \\theta_2 \\neq \\theta_4 \\neq \\theta_5$   \n",
    "$\\theta_7 \\neq \\theta_8 = \\theta_9 \\neq \\theta_{10} = \\theta_{11} $ (All have very close values.)    \n",
    "$\\theta_{28} = \\theta_{29}$   \n",
    "$\\theta_{35} \\neq \\theta_{36} \\neq \\theta_{37} = \\theta_{38} = \\theta_{39} \\neq \\theta_{40}$    \n",
    "$\\theta_{77}$   \n",
    "$\\theta_{93} = \\theta_{94}$   \n",
    "\n",
    "Among coefficients, $\\theta_{37} = \\theta_{38} = \\theta_{39}$ share the highest value and the one with the lowest value is $\\theta_{77}$.\n",
    "\n",
    "Comparing to the coefficients of the **Model A**, **7 variables** that had non-zero coefficients in Model A have its related coefficients both **zero** in this model. Which are: $x_{31}, x_{32}, x_{33}, x_{34}, x_{44}, x_{45}$ and $x_{96} $. Rest of the variables have at least one related coefficient non-zero in Model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task e: Combined Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames(diffstrain) <- paste(\"diff\",colnames(diffstrain),sep=\"\")\n",
    "colnames(diffstest) <- paste(\"diff\",colnames(diffstest),sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combinedtrain = cbind(traindata, diffs = diffstrain)\n",
    "combinedtest = cbind(testdata, diffs = diffstest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 8.362104 \tcvl= -47.37956 \n",
      "lambda= 13.53017 \tcvl= -55.1972 \n",
      "lambda= 5.168065 \tcvl= -41.3855 \n",
      "lambda= 3.19404 \tcvl= -38.45015 \n",
      "lambda= 1.974025 \tcvl= -37.0869 \n",
      "lambda= 1.220015 \tcvl= -38.44436 \n",
      "lambda= 2.206035 \tcvl= -37.22086 \n",
      "lambda= 1.970313 \tcvl= -37.08589 \n",
      "lambda= 1.865786 \tcvl= -37.07762 \n",
      "lambda= 1.619123 \tcvl= -37.38286 \n",
      "lambda= 1.896086 \tcvl= -37.07161 \n",
      "lambda= 1.907468 \tcvl= -37.07384 \n",
      "lambda= 1.891422 \tcvl= -37.07084 \n",
      "lambda= 1.881629 \tcvl= -37.07236 \n",
      "lambda= 1.890024 \tcvl= -37.07062 \n",
      "lambda= 1.886818 \tcvl= -37.07089 \n",
      "lambda= 1.889218 \tcvl= -37.0705 \n",
      "lambda= 1.888301 \tcvl= -37.07049 \n",
      "lambda= 1.88864 \tcvl= -37.07042 \n",
      "lambda= 1.88876 \tcvl= -37.07044 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2c1 <- optL1(response = as.factor(trclass), penalized=combinedtrain ,fusedl = TRUE, fold = 10, model = \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.88864037732801"
      ],
      "text/latex": [
       "1.88864037732801"
      ],
      "text/markdown": [
       "1.88864037732801"
      ],
      "text/plain": [
       "[1] 1.88864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-37.0704181983108"
      ],
      "text/latex": [
       "-37.0704181983108"
      ],
      "text/markdown": [
       "-37.0704181983108"
      ],
      "text/plain": [
       "[1] -37.07042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2c1$lambda; fit2c1$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tuning L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= Inf \tcvl= -63.15148 \n",
      "lambda= 1 \tcvl= -35.75647 \n",
      "lambda= 10 \tcvl= -42.49461 \n",
      "lambda= 0.1 \tcvl= -35.83539 \n",
      "lambda= 3.881464 \tcvl= -39.49009 \n",
      "lambda= 6.218536 \tcvl= -40.82693 \n",
      "lambda= 2.437073 \tcvl= -38.56437 \n",
      "lambda= 1.544391 \tcvl= -36.69081 \n",
      "lambda= 0.9926824 \tcvl= -35.74371 \n",
      "lambda= 0.6517081 \tcvl= -35.41035 \n",
      "lambda= 0.2316834 \tcvl= -35.50094 \n",
      "lambda= 0.5104659 \tcvl= -35.42077 \n",
      "lambda= 0.6535639 \tcvl= -35.41058 \n",
      "lambda= 0.6081957 \tcvl= -35.42521 \n",
      "lambda= 0.6350878 \tcvl= -35.42098 \n",
      "lambda= 0.6453597 \tcvl= -35.41481 \n",
      "lambda= 0.6520333 \tcvl= -35.41075 \n",
      "lambda= 0.6492832 \tcvl= -35.41115 \n",
      "lambda= 0.6507819 \tcvl= -35.41067 \n",
      "lambda= 0.6513543 \tcvl= -35.41071 \n",
      "lambda= 0.651573 \tcvl= -35.41072 \n",
      "lambda= 0.6518323 \tcvl= -35.41074 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2c2 <- optL2(response = as.factor(trclass), penalized=combinedtrain ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda1 = 1.88864037732801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.651708091008328"
      ],
      "text/latex": [
       "0.651708091008328"
      ],
      "text/markdown": [
       "0.651708091008328"
      ],
      "text/plain": [
       "[1] 0.6517081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-35.4103510772348"
      ],
      "text/latex": [
       "-35.4103510772348"
      ],
      "text/markdown": [
       "-35.4103510772348"
      ],
      "text/plain": [
       "[1] -35.41035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2c2$lambda; fit2c2$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cross Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 8.362104 \tcvl= -47.99788 \n",
      "lambda= 13.53017 \tcvl= -56.27814 \n",
      "lambda= 5.168065 \tcvl= -41.79184 \n",
      "lambda= 3.19404 \tcvl= -38.13353 \n",
      "lambda= 1.974025 \tcvl= -35.72225 \n",
      "lambda= 1.220015 \tcvl= -35.07178 \n",
      "lambda= 0.8325308 \tcvl= -36.43173 \n",
      "lambda= 1.484411 \tcvl= -34.95247 \n",
      "lambda= 1.436289 \tcvl= -34.92158 \n",
      "lambda= 1.39685 \tcvl= -34.90618 \n",
      "lambda= 1.329305 \tcvl= -34.98911 \n",
      "lambda= 1.348584 \tcvl= -34.95159 \n",
      "lambda= 1.403707 \tcvl= -34.9069 \n",
      "lambda= 1.394349 \tcvl= -34.90423 \n",
      "lambda= 1.376869 \tcvl= -34.90188 \n",
      "lambda= 1.383525 \tcvl= -34.90157 \n",
      "lambda= 1.3816 \tcvl= -34.90113 \n",
      "lambda= 1.380604 \tcvl= -34.90111 \n",
      "lambda= 1.380932 \tcvl= -34.90104 \n",
      "lambda= 1.381069 \tcvl= -34.90102 \n",
      "lambda= 1.381272 \tcvl= -34.90105 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2c3 <- optL1(response = as.factor(trclass), penalized=combinedtrain ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda2 = 0.651708091008328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.38106887054735"
      ],
      "text/latex": [
       "1.38106887054735"
      ],
      "text/markdown": [
       "1.38106887054735"
      ],
      "text/plain": [
       "[1] 1.381069"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-34.9010170723632"
      ],
      "text/latex": [
       "-34.9010170723632"
      ],
      "text/markdown": [
       "-34.9010170723632"
      ],
      "text/plain": [
       "[1] -34.90102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2c3$lambda; fit2c3$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Re-tuning L2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= Inf \tcvl= -63.15148 \n",
      "lambda= 1 \tcvl= -35.32308 \n",
      "lambda= 10 \tcvl= -42.36754 \n",
      "lambda= 0.1 \tcvl= -36.55996 \n",
      "lambda= 3.881464 \tcvl= -38.79285 \n",
      "lambda= 6.218536 \tcvl= -41.89447 \n",
      "lambda= 2.437073 \tcvl= -37.99506 \n",
      "lambda= 1.811408 \tcvl= -36.84908 \n",
      "lambda= 1.157708 \tcvl= -35.5465 \n",
      "lambda= 0.7536997 \tcvl= -34.91139 \n",
      "lambda= 0.5040086 \tcvl= -35.14379 \n",
      "lambda= 0.7504047 \tcvl= -34.90875 \n",
      "lambda= 0.6951001 \tcvl= -34.8884 \n",
      "lambda= 0.6221097 \tcvl= -34.90989 \n",
      "lambda= 0.6871192 \tcvl= -34.8962 \n",
      "lambda= 0.7140965 \tcvl= -34.88058 \n",
      "lambda= 0.7144154 \tcvl= -34.88081 \n",
      "lambda= 0.7081003 \tcvl= -34.8764 \n",
      "lambda= 0.7031347 \tcvl= -34.87737 \n",
      "lambda= 0.7068165 \tcvl= -34.87574 \n",
      "lambda= 0.7061233 \tcvl= -34.87578 \n",
      "lambda= 0.7065536 \tcvl= -34.87561 \n",
      "lambda= 0.7064883 \tcvl= -34.87558 \n",
      "lambda= 0.7063489 \tcvl= -34.87566 \n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit2c4 <- optL2(response = as.factor(trclass), penalized=combinedtrain ,fusedl = TRUE, fold = 10,\n",
    "                model = \"logistic\", lambda1 = fit2c3$lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.706488317400167"
      ],
      "text/latex": [
       "0.706488317400167"
      ],
      "text/markdown": [
       "0.706488317400167"
      ],
      "text/plain": [
       "[1] 0.7064883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-34.8755833097394"
      ],
      "text/latex": [
       "-34.8755833097394"
      ],
      "text/markdown": [
       "-34.8755833097394"
      ],
      "text/plain": [
       "[1] -34.87558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2c4$lambda; fit2c4$cvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cvl does not improve a lot. We can use this fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.381069 0.7064883"
     ]
    }
   ],
   "source": [
    "l1 = fit2c3$lambda; l2 = fit2c4$lambda; cat(l1,l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set.seed(7)\n",
    "model2c <-penalized(response = as.factor(trclass), penalized = combinedtrain, fusedl = TRUE,\n",
    "                 model = \"logistic\", lambda1 = l1, lambda2 = l2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Penalized logistic regression object\n",
       "192 regression coefficients of which 26 are non-zero\n",
       "\n",
       "Loglikelihood =\t -25.92308 \n",
       "L1 penalty =\t 7.67544 \tat lambda1 =  1.381069 \n",
       "L2 penalty =\t 2.596797 \tat lambda2 =  0.7064883 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2c <- predict(model2c, penalized = combinedtest  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2cClass <- 1*(preds2c >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL A CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2aClass\n",
       "tsclass  0  1\n",
       "      0 24 12\n",
       "      1  6 58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  82 %\n",
      "\n",
      "MODEL B CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2bClass\n",
       "tsclass  0  1\n",
       "      0 27  9\n",
       "      1  7 57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  84 %\n",
      "\n",
      "MODEL C CONFUSION MATRIX"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       preds2cClass\n",
       "tsclass  0  1\n",
       "      0 25 11\n",
       "      1  6 58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  83 %"
     ]
    }
   ],
   "source": [
    "cat(\"MODEL A CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2aClass)  ) )\n",
    "acc = sum(preds2aClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\\n\\n\" )\n",
    "\n",
    "cat(\"MODEL B CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2bClass)  ) )\n",
    "acc = sum(preds2bClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\\n\\n\" )\n",
    "\n",
    "cat(\"MODEL C CONFUSION MATRIX\")\n",
    "table( cbind(Actuals = as.data.frame(tsclass) ,Predictions = as.data.frame(preds2cClass)  ) )\n",
    "acc = sum(preds2cClass == tsclass)/length(tsclass)\n",
    "cat(\"Accuracy is: \",acc*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of the **Model C** resulted between **A** and **B**. The Accuracy value is **83%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task f: Interpreting Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoefficientsC = c(model2c@unpenalized,model2c@penalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.370921061315582</dd>\n",
       "\t<dt>V2</dt>\n",
       "\t\t<dd>-0.174836654098051</dd>\n",
       "\t<dt>V3</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V4</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V5</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V6</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V7</dt>\n",
       "\t\t<dd>-0.204455729810524</dd>\n",
       "\t<dt>V8</dt>\n",
       "\t\t<dd>-0.204455729810524</dd>\n",
       "\t<dt>V9</dt>\n",
       "\t\t<dd>-0.204455729810524</dd>\n",
       "\t<dt>V10</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V11</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V12</dt>\n",
       "\t\t<dd>0.0331995950571946</dd>\n",
       "\t<dt>V13</dt>\n",
       "\t\t<dd>0.359110181682982</dd>\n",
       "\t<dt>V14</dt>\n",
       "\t\t<dd>0.359110181682982</dd>\n",
       "\t<dt>V15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V16</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V17</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V18</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V19</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V20</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V21</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V22</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V23</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V25</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V26</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V27</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V28</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V29</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V30</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V31</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V32</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V33</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V34</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V35</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V36</dt>\n",
       "\t\t<dd>-0.214236242990678</dd>\n",
       "\t<dt>V37</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V38</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V39</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V40</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V41</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V42</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V43</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V44</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V45</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V46</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V47</dt>\n",
       "\t\t<dd>0.152694620223306</dd>\n",
       "\t<dt>V48</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V49</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V50</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V51</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V52</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V53</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V54</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V55</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V56</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V57</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V58</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V59</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V60</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V61</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V62</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V63</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V64</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V65</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V66</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V67</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V68</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V69</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V70</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V71</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V72</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V73</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V74</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V75</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V76</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V77</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V78</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V79</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V80</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V81</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V82</dt>\n",
       "\t\t<dd>-0.0882942484387414</dd>\n",
       "\t<dt>V83</dt>\n",
       "\t\t<dd>-0.0882942484387414</dd>\n",
       "\t<dt>V84</dt>\n",
       "\t\t<dd>-0.0882942484387414</dd>\n",
       "\t<dt>V85</dt>\n",
       "\t\t<dd>-0.0882942484387414</dd>\n",
       "\t<dt>V86</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V87</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V88</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V89</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V90</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V91</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V92</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V93</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V94</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V95</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>V96</dt>\n",
       "\t\t<dd>-0.731611201393364</dd>\n",
       "\t<dt>V97</dt>\n",
       "\t\t<dd>-0.731611201393364</dd>\n",
       "\t<dt>diffV3</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV4</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV5</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV6</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV7</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV8</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV9</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV10</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV11</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV12</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV13</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV14</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV15</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV16</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV17</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV18</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV19</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV20</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV21</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV22</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV23</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV24</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV25</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV26</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV27</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV28</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV29</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV30</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV31</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV32</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV33</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV34</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV35</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV36</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV37</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV38</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV39</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV40</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV41</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV42</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV43</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV44</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV45</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV46</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV47</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV48</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV49</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV50</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV51</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV52</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV53</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV54</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV55</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV56</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV57</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV58</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV59</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV60</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV61</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV62</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV63</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV64</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV65</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV66</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV67</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV68</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV69</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV70</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV71</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV72</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV73</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV74</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV75</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV76</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV77</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV78</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV79</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV80</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV81</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV82</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV83</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV84</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV85</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV86</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV87</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV88</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV89</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV90</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV91</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV92</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV93</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV94</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV95</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV96</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>diffV97</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.370921061315582\n",
       "\\item[V2] -0.174836654098051\n",
       "\\item[V3] 0\n",
       "\\item[V4] 0\n",
       "\\item[V5] 0\n",
       "\\item[V6] 0\n",
       "\\item[V7] -0.204455729810524\n",
       "\\item[V8] -0.204455729810524\n",
       "\\item[V9] -0.204455729810524\n",
       "\\item[V10] 0\n",
       "\\item[V11] 0\n",
       "\\item[V12] 0.0331995950571946\n",
       "\\item[V13] 0.359110181682982\n",
       "\\item[V14] 0.359110181682982\n",
       "\\item[V15] 0\n",
       "\\item[V16] 0\n",
       "\\item[V17] 0\n",
       "\\item[V18] 0\n",
       "\\item[V19] 0\n",
       "\\item[V20] 0\n",
       "\\item[V21] 0\n",
       "\\item[V22] 0\n",
       "\\item[V23] 0\n",
       "\\item[V24] 0\n",
       "\\item[V25] 0\n",
       "\\item[V26] 0\n",
       "\\item[V27] 0\n",
       "\\item[V28] 0\n",
       "\\item[V29] 0\n",
       "\\item[V30] 0\n",
       "\\item[V31] -0.214236242990678\n",
       "\\item[V32] -0.214236242990678\n",
       "\\item[V33] -0.214236242990678\n",
       "\\item[V34] -0.214236242990678\n",
       "\\item[V35] -0.214236242990678\n",
       "\\item[V36] -0.214236242990678\n",
       "\\item[V37] 0\n",
       "\\item[V38] 0\n",
       "\\item[V39] 0\n",
       "\\item[V40] 0\n",
       "\\item[V41] 0\n",
       "\\item[V42] 0.152694620223306\n",
       "\\item[V43] 0.152694620223306\n",
       "\\item[V44] 0.152694620223306\n",
       "\\item[V45] 0.152694620223306\n",
       "\\item[V46] 0.152694620223306\n",
       "\\item[V47] 0.152694620223306\n",
       "\\item[V48] 0\n",
       "\\item[V49] 0\n",
       "\\item[V50] 0\n",
       "\\item[V51] 0\n",
       "\\item[V52] 0\n",
       "\\item[V53] 0\n",
       "\\item[V54] 0\n",
       "\\item[V55] 0\n",
       "\\item[V56] 0\n",
       "\\item[V57] 0\n",
       "\\item[V58] 0\n",
       "\\item[V59] 0\n",
       "\\item[V60] 0\n",
       "\\item[V61] 0\n",
       "\\item[V62] 0\n",
       "\\item[V63] 0\n",
       "\\item[V64] 0\n",
       "\\item[V65] 0\n",
       "\\item[V66] 0\n",
       "\\item[V67] 0\n",
       "\\item[V68] 0\n",
       "\\item[V69] 0\n",
       "\\item[V70] 0\n",
       "\\item[V71] 0\n",
       "\\item[V72] 0\n",
       "\\item[V73] 0\n",
       "\\item[V74] 0\n",
       "\\item[V75] 0\n",
       "\\item[V76] 0\n",
       "\\item[V77] 0\n",
       "\\item[V78] 0\n",
       "\\item[V79] 0\n",
       "\\item[V80] 0\n",
       "\\item[V81] 0\n",
       "\\item[V82] -0.0882942484387414\n",
       "\\item[V83] -0.0882942484387414\n",
       "\\item[V84] -0.0882942484387414\n",
       "\\item[V85] -0.0882942484387414\n",
       "\\item[V86] 0\n",
       "\\item[V87] 0\n",
       "\\item[V88] 0\n",
       "\\item[V89] 0\n",
       "\\item[V90] 0\n",
       "\\item[V91] 0\n",
       "\\item[V92] 0\n",
       "\\item[V93] 0\n",
       "\\item[V94] 0\n",
       "\\item[V95] 0\n",
       "\\item[V96] -0.731611201393364\n",
       "\\item[V97] -0.731611201393364\n",
       "\\item[diffV3] 0\n",
       "\\item[diffV4] 0\n",
       "\\item[diffV5] 0\n",
       "\\item[diffV6] 0\n",
       "\\item[diffV7] 0\n",
       "\\item[diffV8] 0\n",
       "\\item[diffV9] 0\n",
       "\\item[diffV10] 0\n",
       "\\item[diffV11] 0\n",
       "\\item[diffV12] 0\n",
       "\\item[diffV13] 0\n",
       "\\item[diffV14] 0\n",
       "\\item[diffV15] 0\n",
       "\\item[diffV16] 0\n",
       "\\item[diffV17] 0\n",
       "\\item[diffV18] 0\n",
       "\\item[diffV19] 0\n",
       "\\item[diffV20] 0\n",
       "\\item[diffV21] 0\n",
       "\\item[diffV22] 0\n",
       "\\item[diffV23] 0\n",
       "\\item[diffV24] 0\n",
       "\\item[diffV25] 0\n",
       "\\item[diffV26] 0\n",
       "\\item[diffV27] 0\n",
       "\\item[diffV28] 0\n",
       "\\item[diffV29] 0\n",
       "\\item[diffV30] 0\n",
       "\\item[diffV31] 0\n",
       "\\item[diffV32] 0\n",
       "\\item[diffV33] 0\n",
       "\\item[diffV34] 0\n",
       "\\item[diffV35] 0\n",
       "\\item[diffV36] 0\n",
       "\\item[diffV37] 0\n",
       "\\item[diffV38] 0\n",
       "\\item[diffV39] 0\n",
       "\\item[diffV40] 0\n",
       "\\item[diffV41] 0\n",
       "\\item[diffV42] 0\n",
       "\\item[diffV43] 0\n",
       "\\item[diffV44] 0\n",
       "\\item[diffV45] 0\n",
       "\\item[diffV46] 0\n",
       "\\item[diffV47] 0\n",
       "\\item[diffV48] 0\n",
       "\\item[diffV49] 0\n",
       "\\item[diffV50] 0\n",
       "\\item[diffV51] 0\n",
       "\\item[diffV52] 0\n",
       "\\item[diffV53] 0\n",
       "\\item[diffV54] 0\n",
       "\\item[diffV55] 0\n",
       "\\item[diffV56] 0\n",
       "\\item[diffV57] 0\n",
       "\\item[diffV58] 0\n",
       "\\item[diffV59] 0\n",
       "\\item[diffV60] 0\n",
       "\\item[diffV61] 0\n",
       "\\item[diffV62] 0\n",
       "\\item[diffV63] 0\n",
       "\\item[diffV64] 0\n",
       "\\item[diffV65] 0\n",
       "\\item[diffV66] 0\n",
       "\\item[diffV67] 0\n",
       "\\item[diffV68] 0\n",
       "\\item[diffV69] 0\n",
       "\\item[diffV70] 0\n",
       "\\item[diffV71] 0\n",
       "\\item[diffV72] 0\n",
       "\\item[diffV73] 0\n",
       "\\item[diffV74] 0\n",
       "\\item[diffV75] 0\n",
       "\\item[diffV76] 0\n",
       "\\item[diffV77] 0\n",
       "\\item[diffV78] 0\n",
       "\\item[diffV79] 0\n",
       "\\item[diffV80] 0\n",
       "\\item[diffV81] 0\n",
       "\\item[diffV82] 0\n",
       "\\item[diffV83] 0\n",
       "\\item[diffV84] 0\n",
       "\\item[diffV85] 0\n",
       "\\item[diffV86] 0\n",
       "\\item[diffV87] 0\n",
       "\\item[diffV88] 0\n",
       "\\item[diffV89] 0\n",
       "\\item[diffV90] 0\n",
       "\\item[diffV91] 0\n",
       "\\item[diffV92] 0\n",
       "\\item[diffV93] 0\n",
       "\\item[diffV94] 0\n",
       "\\item[diffV95] 0\n",
       "\\item[diffV96] 0\n",
       "\\item[diffV97] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.370921061315582V2\n",
       ":   -0.174836654098051V3\n",
       ":   0V4\n",
       ":   0V5\n",
       ":   0V6\n",
       ":   0V7\n",
       ":   -0.204455729810524V8\n",
       ":   -0.204455729810524V9\n",
       ":   -0.204455729810524V10\n",
       ":   0V11\n",
       ":   0V12\n",
       ":   0.0331995950571946V13\n",
       ":   0.359110181682982V14\n",
       ":   0.359110181682982V15\n",
       ":   0V16\n",
       ":   0V17\n",
       ":   0V18\n",
       ":   0V19\n",
       ":   0V20\n",
       ":   0V21\n",
       ":   0V22\n",
       ":   0V23\n",
       ":   0V24\n",
       ":   0V25\n",
       ":   0V26\n",
       ":   0V27\n",
       ":   0V28\n",
       ":   0V29\n",
       ":   0V30\n",
       ":   0V31\n",
       ":   -0.214236242990678V32\n",
       ":   -0.214236242990678V33\n",
       ":   -0.214236242990678V34\n",
       ":   -0.214236242990678V35\n",
       ":   -0.214236242990678V36\n",
       ":   -0.214236242990678V37\n",
       ":   0V38\n",
       ":   0V39\n",
       ":   0V40\n",
       ":   0V41\n",
       ":   0V42\n",
       ":   0.152694620223306V43\n",
       ":   0.152694620223306V44\n",
       ":   0.152694620223306V45\n",
       ":   0.152694620223306V46\n",
       ":   0.152694620223306V47\n",
       ":   0.152694620223306V48\n",
       ":   0V49\n",
       ":   0V50\n",
       ":   0V51\n",
       ":   0V52\n",
       ":   0V53\n",
       ":   0V54\n",
       ":   0V55\n",
       ":   0V56\n",
       ":   0V57\n",
       ":   0V58\n",
       ":   0V59\n",
       ":   0V60\n",
       ":   0V61\n",
       ":   0V62\n",
       ":   0V63\n",
       ":   0V64\n",
       ":   0V65\n",
       ":   0V66\n",
       ":   0V67\n",
       ":   0V68\n",
       ":   0V69\n",
       ":   0V70\n",
       ":   0V71\n",
       ":   0V72\n",
       ":   0V73\n",
       ":   0V74\n",
       ":   0V75\n",
       ":   0V76\n",
       ":   0V77\n",
       ":   0V78\n",
       ":   0V79\n",
       ":   0V80\n",
       ":   0V81\n",
       ":   0V82\n",
       ":   -0.0882942484387414V83\n",
       ":   -0.0882942484387414V84\n",
       ":   -0.0882942484387414V85\n",
       ":   -0.0882942484387414V86\n",
       ":   0V87\n",
       ":   0V88\n",
       ":   0V89\n",
       ":   0V90\n",
       ":   0V91\n",
       ":   0V92\n",
       ":   0V93\n",
       ":   0V94\n",
       ":   0V95\n",
       ":   0V96\n",
       ":   -0.731611201393364V97\n",
       ":   -0.731611201393364diffV3\n",
       ":   0diffV4\n",
       ":   0diffV5\n",
       ":   0diffV6\n",
       ":   0diffV7\n",
       ":   0diffV8\n",
       ":   0diffV9\n",
       ":   0diffV10\n",
       ":   0diffV11\n",
       ":   0diffV12\n",
       ":   0diffV13\n",
       ":   0diffV14\n",
       ":   0diffV15\n",
       ":   0diffV16\n",
       ":   0diffV17\n",
       ":   0diffV18\n",
       ":   0diffV19\n",
       ":   0diffV20\n",
       ":   0diffV21\n",
       ":   0diffV22\n",
       ":   0diffV23\n",
       ":   0diffV24\n",
       ":   0diffV25\n",
       ":   0diffV26\n",
       ":   0diffV27\n",
       ":   0diffV28\n",
       ":   0diffV29\n",
       ":   0diffV30\n",
       ":   0diffV31\n",
       ":   0diffV32\n",
       ":   0diffV33\n",
       ":   0diffV34\n",
       ":   0diffV35\n",
       ":   0diffV36\n",
       ":   0diffV37\n",
       ":   0diffV38\n",
       ":   0diffV39\n",
       ":   0diffV40\n",
       ":   0diffV41\n",
       ":   0diffV42\n",
       ":   0diffV43\n",
       ":   0diffV44\n",
       ":   0diffV45\n",
       ":   0diffV46\n",
       ":   0diffV47\n",
       ":   0diffV48\n",
       ":   0diffV49\n",
       ":   0diffV50\n",
       ":   0diffV51\n",
       ":   0diffV52\n",
       ":   0diffV53\n",
       ":   0diffV54\n",
       ":   0diffV55\n",
       ":   0diffV56\n",
       ":   0diffV57\n",
       ":   0diffV58\n",
       ":   0diffV59\n",
       ":   0diffV60\n",
       ":   0diffV61\n",
       ":   0diffV62\n",
       ":   0diffV63\n",
       ":   0diffV64\n",
       ":   0diffV65\n",
       ":   0diffV66\n",
       ":   0diffV67\n",
       ":   0diffV68\n",
       ":   0diffV69\n",
       ":   0diffV70\n",
       ":   0diffV71\n",
       ":   0diffV72\n",
       ":   0diffV73\n",
       ":   0diffV74\n",
       ":   0diffV75\n",
       ":   0diffV76\n",
       ":   0diffV77\n",
       ":   0diffV78\n",
       ":   0diffV79\n",
       ":   0diffV80\n",
       ":   0diffV81\n",
       ":   0diffV82\n",
       ":   0diffV83\n",
       ":   0diffV84\n",
       ":   0diffV85\n",
       ":   0diffV86\n",
       ":   0diffV87\n",
       ":   0diffV88\n",
       ":   0diffV89\n",
       ":   0diffV90\n",
       ":   0diffV91\n",
       ":   0diffV92\n",
       ":   0diffV93\n",
       ":   0diffV94\n",
       ":   0diffV95\n",
       ":   0diffV96\n",
       ":   0diffV97\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)          V2          V3          V4          V5          V6 \n",
       " 0.37092106 -0.17483665  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "         V7          V8          V9         V10         V11         V12 \n",
       "-0.20445573 -0.20445573 -0.20445573  0.00000000  0.00000000  0.03319960 \n",
       "        V13         V14         V15         V16         V17         V18 \n",
       " 0.35911018  0.35911018  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V19         V20         V21         V22         V23         V24 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V25         V26         V27         V28         V29         V30 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V31         V32         V33         V34         V35         V36 \n",
       "-0.21423624 -0.21423624 -0.21423624 -0.21423624 -0.21423624 -0.21423624 \n",
       "        V37         V38         V39         V40         V41         V42 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.15269462 \n",
       "        V43         V44         V45         V46         V47         V48 \n",
       " 0.15269462  0.15269462  0.15269462  0.15269462  0.15269462  0.00000000 \n",
       "        V49         V50         V51         V52         V53         V54 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V55         V56         V57         V58         V59         V60 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V61         V62         V63         V64         V65         V66 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V67         V68         V69         V70         V71         V72 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V73         V74         V75         V76         V77         V78 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V79         V80         V81         V82         V83         V84 \n",
       " 0.00000000  0.00000000  0.00000000 -0.08829425 -0.08829425 -0.08829425 \n",
       "        V85         V86         V87         V88         V89         V90 \n",
       "-0.08829425  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "        V91         V92         V93         V94         V95         V96 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 -0.73161120 \n",
       "        V97      diffV3      diffV4      diffV5      diffV6      diffV7 \n",
       "-0.73161120  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "     diffV8      diffV9     diffV10     diffV11     diffV12     diffV13 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV14     diffV15     diffV16     diffV17     diffV18     diffV19 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV20     diffV21     diffV22     diffV23     diffV24     diffV25 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV26     diffV27     diffV28     diffV29     diffV30     diffV31 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV32     diffV33     diffV34     diffV35     diffV36     diffV37 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV38     diffV39     diffV40     diffV41     diffV42     diffV43 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV44     diffV45     diffV46     diffV47     diffV48     diffV49 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV50     diffV51     diffV52     diffV53     diffV54     diffV55 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV56     diffV57     diffV58     diffV59     diffV60     diffV61 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV62     diffV63     diffV64     diffV65     diffV66     diffV67 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV68     diffV69     diffV70     diffV71     diffV72     diffV73 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV74     diffV75     diffV76     diffV77     diffV78     diffV79 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV80     diffV81     diffV82     diffV83     diffV84     diffV85 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV86     diffV87     diffV88     diffV89     diffV90     diffV91 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 \n",
       "    diffV92     diffV93     diffV94     diffV95     diffV96     diffV97 \n",
       " 0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CoefficientsC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "26"
      ],
      "text/latex": [
       "26"
      ],
      "text/markdown": [
       "26"
      ],
      "text/plain": [
       "[1] 26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(coef(model2c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>100</li>\n",
       "\t<li>191</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 100\n",
       "\\item 191\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 100\n",
       "2. 191\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 100 191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(combinedtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**26** coefficients of the model is not equal to zero out of **191**. Number of non-zero coefficients is increased but ratio of the number of non-zero coefficients is the lowest in this model. Looking at the cooefficients, only those belong to the **Model A** are non-zero. Somewhat we have a model very similar to the model A but with better results.  \n",
    "\n",
    "All coefficients that are non-zero in the Model A are non-zero in this model as well. Additionally, $\\theta_8$, $\\theta_{11}$, $\\theta_{13}$, $\\theta_{41}$, $\\theta_{42}$, $\\theta_{43}$, $\\theta_{46}$, $\\theta_{81}$, $\\theta_{82}$, $\\theta_{83}$ and $\\theta_{84}$. Also, these coefficients are equal:\n",
    "\n",
    "$\\theta_6 = \\theta_7 = \\theta_8$    \n",
    "$\\theta_{12} = \\theta_{13}$    \n",
    "$\\theta_{30} = \\theta_{31} = \\theta_{32} = \\theta_{33} = \\theta_{34} = \\theta_{35}$    \n",
    "$\\theta_{41} = \\theta_{42} = \\theta_{43} = \\theta_{44} = \\theta_{45} = \\theta_{46}$    \n",
    "$\\theta_{81} = \\theta_{82} = \\theta_{83} = \\theta_{84}$    \n",
    "$\\theta_{95} = \\theta_{96}$ \n",
    "\n",
    "Looking the equations above, we have longer sequences of equal coefficients in this model different from previous models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
